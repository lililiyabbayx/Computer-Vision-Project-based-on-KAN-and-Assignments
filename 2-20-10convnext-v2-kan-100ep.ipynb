{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 2B: CPU-only reinstall\n!pip uninstall -y torch torchvision torchaudio\n!pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cpu \\\n    torch torchvision torchaudio\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-20T07:51:25.552060Z","iopub.execute_input":"2025-10-20T07:51:25.552454Z","iopub.status.idle":"2025-10-20T07:51:52.428372Z","shell.execute_reply.started":"2025-10-20T07:51:25.552425Z","shell.execute_reply":"2025-10-20T07:51:52.427650Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.9.0+cpu\nUninstalling torch-2.9.0+cpu:\n  Successfully uninstalled torch-2.9.0+cpu\nFound existing installation: torchvision 0.24.0+cpu\nUninstalling torchvision-0.24.0+cpu:\n  Successfully uninstalled torchvision-0.24.0+cpu\nFound existing installation: torchaudio 2.9.0+cpu\nUninstalling torchaudio-2.9.0+cpu:\n  Successfully uninstalled torchaudio-2.9.0+cpu\nLooking in indexes: https://download.pytorch.org/whl/cpu\nCollecting torch\n  Downloading https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting torchvision\n  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\nCollecting torchaudio\n  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2025.9.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nDownloading https://download.pytorch.org/whl/cpu/torch-2.9.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (184.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 MB\u001b[0m \u001b[31m326.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.24.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m346.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.9.0%2Bcpu-cp311-cp311-manylinux_2_28_x86_64.whl (494 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.9/494.9 kB\u001b[0m \u001b[31m322.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torch, torchaudio, torchvision\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nfastai 2.8.4 requires torch<2.9,>=1.10, but you have torch 2.9.0+cpu which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed torch-2.9.0+cpu torchaudio-2.9.0+cpu torchvision-0.24.0+cpu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T08:10:18.511019Z","iopub.execute_input":"2025-10-20T08:10:18.511329Z","iopub.status.idle":"2025-10-20T08:10:18.515017Z","shell.execute_reply.started":"2025-10-20T08:10:18.511308Z","shell.execute_reply":"2025-10-20T08:10:18.514350Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import torch\nprint(\"torch:\", torch.__version__, \"from\", getattr(torch, \"__file__\", \"n/a\"))\nprint(\"cuda available:\", torch.cuda.is_available())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T08:10:10.112993Z","iopub.execute_input":"2025-10-20T08:10:10.113511Z","iopub.status.idle":"2025-10-20T08:10:13.846738Z","shell.execute_reply.started":"2025-10-20T08:10:10.113491Z","shell.execute_reply":"2025-10-20T08:10:13.845910Z"}},"outputs":[{"name":"stdout","text":"torch: 2.6.0+cu124 from /usr/local/lib/python3.11/dist-packages/torch/__init__.py\ncuda available: True\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# full_convnextv2_with_kan_and_runner.py\n# Single-file: ConvNeXtV2 variants (baseline / SE / KAN / SE+KAN) + KAN + training runner for Kaggle dataset.\n# Usage: paste into a notebook cell on Kaggle and run. DATA_ROOT defaults to /kaggle/input/brain-tumor-mri-dataset\n\nimport os, math, random, warnings\nfrom copy import deepcopy\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T\nfrom torch.utils.data import Dataset, DataLoader\n\n# -------------------- Basic utilities & deterministic seed --------------------\n\ndef ensure_dir(path):\n    os.makedirs(path, exist_ok=True)\n\ndef set_global_seed(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    # deterministic cudnn for reproducibility (may slow down)\n    try:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n    except Exception:\n        pass\n    if torch.cuda.is_available():\n        try:\n            torch.cuda.manual_seed_all(seed)\n        except Exception:\n            pass\n\ndef safe_train_test_split(df, **kwargs):\n    try:\n        return train_test_split(df, **kwargs)\n    except Exception:\n        stratify = kwargs.pop('stratify', None)\n        try:\n            return train_test_split(df, stratify=None, **kwargs)\n        except Exception:\n            if len(df) == 0:\n                return df.copy(), df.copy()\n            n = len(df)\n            test_size = kwargs.get('test_size', 0.15)\n            if isinstance(test_size, float):\n                n_test = max(1, int(math.ceil(n * test_size)))\n            else:\n                n_test = int(test_size)\n            if n_test >= n:\n                n_test = max(1, n//10)\n            idx = list(range(n)); random.shuffle(idx)\n            test_idx = idx[:n_test]; train_idx = idx[n_test:]\n            df_train = df.iloc[train_idx].reset_index(drop=True)\n            df_test  = df.iloc[test_idx].reset_index(drop=True)\n            return df_train, df_test\n\ndef get_class_paths(path):\n    if not os.path.isdir(path):\n        return pd.DataFrame(columns=['path','label'])\n    paths, labels = [], []\n    for label in sorted(os.listdir(path)):\n        label_path = os.path.join(path, label)\n        if not os.path.isdir(label_path):\n            continue\n        for fname in sorted(os.listdir(label_path)):\n            ext = os.path.splitext(fname)[1].lower()\n            if ext in ('.jpg','.jpeg','.png','.webp'):\n                paths.append(os.path.join(label_path, fname))\n                labels.append(label)\n    return pd.DataFrame({'path':paths, 'label':labels})\n\nclass MRIDataset(Dataset):\n    def __init__(self, df, label2idx, transforms=None):\n        self.df = df.reset_index(drop=True)\n        self.transforms = transforms\n        self.label2idx = label2idx\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['path']).convert('RGB')\n        if self.transforms: img = self.transforms(img)\n        else: img = T.ToTensor()(img)\n        lbl = self.label2idx[row['label']]\n        return img, int(lbl)\n\n# -------------------- ConvNeXt helper utilities (trunc_normal_, drop_path, LayerNorm, GRN) --------------------\n\ndef _trunc_normal_(tensor, mean, std, a, b):\n    # truncated normal (copied from many reference impls)\n    def norm_cdf(x):\n        return (1.0 + math.erf(x / math.sqrt(2.0))) / 2.0\n    if (mean < a - 2 * std) or (mean > b + 2 * std):\n        warnings.warn(\"mean is more than 2 std from [a, b] in nn.init.trunc_normal_.\", stacklevel=2)\n    l = norm_cdf((a - mean) / std); u = norm_cdf((b - mean) / std)\n    tensor.uniform_(2 * l - 1, 2 * u - 1); tensor.erfinv_()\n    tensor.mul_(std * math.sqrt(2.0)); tensor.add_(mean)\n    tensor.clamp_(min=a, max=b)\n    return tensor\n\ndef trunc_normal_(tensor, mean=0.0, std=1.0, a=-2.0, b=2.0):\n    with torch.no_grad():\n        return _trunc_normal_(tensor, mean, std, a, b)\n\ndef drop_path(x, drop_prob: float = 0.0, training: bool = False, scale_by_keep: bool = True):\n    if drop_prob == 0.0 or not training:\n        return x\n    keep_prob = 1 - drop_prob\n    shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n    random_tensor = x.new_empty(shape).bernoulli_(keep_prob)\n    if keep_prob > 0.0 and scale_by_keep:\n        random_tensor.div_(keep_prob)\n    return x * random_tensor\n\nclass DropPath(nn.Module):\n    def __init__(self, drop_prob: float = 0.0, scale_by_keep: bool = True):\n        super().__init__()\n        self.drop_prob = drop_prob\n        self.scale_by_keep = scale_by_keep\n    def forward(self, x):\n        return drop_path(x, self.drop_prob, self.training, self.scale_by_keep)\n    def extra_repr(self):\n        return f\"drop_prob={round(self.drop_prob,3):0.3f}\"\n\nclass LayerNorm(nn.Module):\n    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n        super().__init__()\n        self.weight = nn.Parameter(torch.ones(normalized_shape))\n        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n        self.eps = eps\n        self.data_format = data_format\n        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n            raise NotImplementedError\n        self.normalized_shape = (normalized_shape,)\n    def forward(self, x):\n        if self.data_format == \"channels_last\":\n            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n        elif self.data_format == \"channels_first\":\n            u = x.mean(1, keepdim=True)\n            s = (x - u).pow(2).mean(1, keepdim=True)\n            x = (x - u) / torch.sqrt(s + self.eps)\n            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n            return x\n\nclass GRN(nn.Module):\n    def __init__(self, dim):\n        super().__init__()\n        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n    def forward(self, x):\n        Gx = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n        return self.gamma * (x * Nx) + self.beta + x\n\n# -------------------- KAN implementation --------------------\n\nclass KANLinear(torch.nn.Module):\n    def __init__(\n        self,\n        in_features,\n        out_features,\n        grid_size=5,\n        spline_order=3,\n        scale_noise=0.1,\n        scale_base=1.0,\n        scale_spline=1.0,\n        enable_standalone_scale_spline=True,\n        base_activation=torch.nn.SiLU,\n        grid_eps=0.02,\n        grid_range=[-1, 1],\n    ):\n        super(KANLinear, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n\n        h = (grid_range[1] - grid_range[0]) / grid_size\n        grid = (\n            (\n                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n                + grid_range[0]\n            )\n            .expand(in_features, -1)\n            .contiguous()\n        )\n        self.register_buffer(\"grid\", grid)\n\n        self.base_weight = torch.nn.Parameter(torch.Tensor(out_features, in_features))\n        self.spline_weight = torch.nn.Parameter(\n            torch.Tensor(out_features, in_features, grid_size + spline_order)\n        )\n        if enable_standalone_scale_spline:\n            self.spline_scaler = torch.nn.Parameter(\n                torch.Tensor(out_features, in_features)\n            )\n\n        self.scale_noise = scale_noise\n        self.scale_base = scale_base\n        self.scale_spline = scale_spline\n        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n        self.base_activation = base_activation()\n        self.grid_eps = grid_eps\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        torch.nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n        with torch.no_grad():\n            noise = (\n                (\n                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n                    - 1 / 2\n                )\n                * self.scale_noise\n                / self.grid_size\n            )\n            self.spline_weight.data.copy_(\n                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n                * self.curve2coeff(\n                    self.grid.T[self.spline_order : -self.spline_order],\n                    noise,\n                )\n            )\n            if self.enable_standalone_scale_spline:\n                torch.nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n\n    def b_splines(self, x: torch.Tensor):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        grid: torch.Tensor = self.grid\n        x = x.unsqueeze(-1)\n        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n        for k in range(1, self.spline_order + 1):\n            bases = (\n                (x - grid[:, : -(k + 1)]) / (grid[:, k:-1] - grid[:, : -(k + 1)]) * bases[:, :, :-1]\n            ) + (\n                (grid[:, k + 1 :] - x) / (grid[:, k + 1 :] - grid[:, 1:(-k)]) * bases[:, :, 1:]\n            )\n        assert bases.size() == (x.size(0), self.in_features, self.grid_size + self.spline_order)\n        return bases.contiguous()\n\n    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        assert y.size() == (x.size(0), self.in_features, self.out_features)\n        A = self.b_splines(x).transpose(0, 1)\n        B = y.transpose(0, 1)\n        solution = torch.linalg.lstsq(A, B).solution\n        result = solution.permute(2, 0, 1)\n        assert result.size() == (self.out_features, self.in_features, self.grid_size + self.spline_order)\n        return result.contiguous()\n\n    @property\n    def scaled_spline_weight(self):\n        return self.spline_weight * (self.spline_scaler.unsqueeze(-1) if self.enable_standalone_scale_spline else 1.0)\n\n    def forward(self, x: torch.Tensor):\n        orig_shape = x.shape\n        x2 = x.reshape(-1, self.in_features)\n        base_output = F.linear(self.base_activation(x2), self.base_weight)\n        spline_output = F.linear(\n            self.b_splines(x2).view(x2.size(0), -1),\n            self.scaled_spline_weight.view(self.out_features, -1),\n        )\n        output = base_output + spline_output\n        output = output.reshape(*orig_shape[:-1], self.out_features)\n        return output\n\n    @torch.no_grad()\n    def update_grid(self, x: torch.Tensor, margin=0.01):\n        assert x.dim() == 2 and x.size(1) == self.in_features\n        batch = x.size(0)\n        splines = self.b_splines(x).permute(1, 0, 2)\n        orig_coeff = self.scaled_spline_weight.permute(1, 2, 0)\n        unreduced_spline_output = torch.bmm(splines, orig_coeff).permute(1, 0, 2)\n        x_sorted = torch.sort(x, dim=0)[0]\n        grid_adaptive = x_sorted[torch.linspace(0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device)]\n        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n        grid_uniform = (torch.arange(self.grid_size + 1, dtype=torch.float32, device=x.device).unsqueeze(1) * uniform_step + x_sorted[0] - margin)\n        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n        grid = torch.concatenate([\n            grid[:1] - uniform_step * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n            grid,\n            grid[-1:] + uniform_step * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n        ], dim=0)\n        self.grid.copy_(grid.T)\n        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        l1_fake = self.spline_weight.abs().mean(-1)\n        regularization_loss_activation = l1_fake.sum()\n        p = l1_fake / (regularization_loss_activation + 1e-12)\n        regularization_loss_entropy = -torch.sum(p * (p + 1e-12).log())\n        return (regularize_activation * regularization_loss_activation + regularize_entropy * regularization_loss_entropy)\n\n\nclass KAN(torch.nn.Module):\n    def __init__(self, layers_hidden, grid_size=5, spline_order=3, scale_noise=0.1, scale_base=1.0, scale_spline=1.0, base_activation=torch.nn.SiLU, grid_eps=0.02, grid_range=[-1,1]):\n        super(KAN, self).__init__()\n        self.grid_size = grid_size\n        self.spline_order = spline_order\n        self.layers = torch.nn.ModuleList()\n        for in_features, out_features in zip(layers_hidden, layers_hidden[1:]):\n            self.layers.append(\n                KANLinear(\n                    in_features,\n                    out_features,\n                    grid_size=grid_size,\n                    spline_order=spline_order,\n                    scale_noise=scale_noise,\n                    scale_base=scale_base,\n                    scale_spline=scale_spline,\n                    base_activation=base_activation,\n                    grid_eps=grid_eps,\n                    grid_range=grid_range,\n                )\n            )\n    def forward(self, x: torch.Tensor, update_grid=False):\n        orig_shape = x.shape\n        x_flat = x.reshape(-1, orig_shape[-1])\n        out = x_flat\n        for layer in self.layers:\n            if update_grid:\n                layer.update_grid(out)\n            out = layer(out)\n        out = out.reshape(*orig_shape[:-1], out.shape[-1])\n        return out\n    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n        return sum(layer.regularization_loss(regularize_activation, regularize_entropy) for layer in self.layers)\n\n# -------------------- ConvNeXtV2 Blocks --------------------\n\nclass ConvNeXtBlockBaseline(nn.Module):\n    def __init__(self, dim, drop_path=0.0):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n        self.norm = LayerNorm(dim, eps=1e-6)  # channels_last\n        self.pw1 = nn.Linear(dim, 4 * dim)\n        self.act = nn.GELU()\n        self.grn = GRN(4 * dim)\n        self.pw2 = nn.Linear(4 * dim, dim)\n        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n    def forward(self, x):\n        shortcut = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1)   # (N,H,W,C)\n        x = self.norm(x)\n        x = self.pw1(x)\n        x = self.act(x)\n        x = self.grn(x)\n        x = self.pw2(x)\n        x = x.permute(0, 3, 1, 2)   # back to (N,C,H,W)\n        x = shortcut + self.drop_path(x)\n        return x\n\nclass ConvNeXtBlockSE(nn.Module):\n    def __init__(self, dim, drop_path=0.0, se_reduction=4):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.pw1 = nn.Linear(dim, 4 * dim)\n        self.act = nn.GELU()\n        self.grn = GRN(4 * dim)\n        self.pw2 = nn.Linear(4 * dim, dim)\n        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n\n        hidden = max(1, dim // se_reduction)\n        self.se_fc1 = nn.Linear(dim, hidden)\n        self.se_act = nn.GELU()\n        self.se_fc2 = nn.Linear(hidden, dim)\n        self.se_sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        shortcut = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1)   # (N,H,W,C)\n        x = self.norm(x)\n        x = self.pw1(x)\n        x = self.act(x)\n        x = self.grn(x)\n        x = self.pw2(x)\n\n        se = x.mean(dim=(1, 2))              # (N, C)\n        se = self.se_fc1(se)\n        se = self.se_act(se)\n        se = self.se_fc2(se)\n        se = self.se_sigmoid(se).unsqueeze(1).unsqueeze(1)  # (N,1,1,C)\n        x = x * se\n\n        x = x.permute(0, 3, 1, 2)\n        x = shortcut + self.drop_path(x)\n        return x\n\nclass ConvNeXtBlockKAN(nn.Module):\n    def __init__(self, dim, drop_path=0.0, kan_grid_size=5, kan_spline_order=3):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.kan1 = KAN([dim, 4 * dim], grid_size=kan_grid_size, spline_order=kan_spline_order)\n        self.act = nn.GELU()\n        self.grn = GRN(4 * dim)\n        self.kan2 = KAN([4 * dim, dim], grid_size=kan_grid_size, spline_order=kan_spline_order)\n        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n    def forward(self, x):\n        shortcut = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1)  # (N,H,W,C)\n        x = self.norm(x)\n        N, H, W, C = x.shape\n        x_flat = x.reshape(-1, C)\n        x_flat = self.kan1(x_flat)\n        x = x_flat.reshape(N, H, W, 4 * C)\n        x = self.act(x)\n        x = self.grn(x)\n        x_flat2 = x.reshape(-1, 4 * C)\n        x_flat2 = self.kan2(x_flat2)\n        x = x_flat2.reshape(N, H, W, C)\n        x = x.permute(0, 3, 1, 2)\n        x = shortcut + self.drop_path(x)\n        return x\n\nclass ConvNeXtBlockSEKAN(nn.Module):\n    def __init__(self, dim, drop_path=0.0, se_reduction=4, kan_grid_size=5, kan_spline_order=3):\n        super().__init__()\n        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)\n        self.norm = LayerNorm(dim, eps=1e-6)\n        self.kan1 = KAN([dim, 4 * dim], grid_size=kan_grid_size, spline_order=kan_spline_order)\n        self.act = nn.GELU()\n        self.grn = GRN(4 * dim)\n        self.kan2 = KAN([4 * dim, dim], grid_size=kan_grid_size, spline_order=kan_spline_order)\n        self.drop_path = DropPath(drop_path) if drop_path > 0.0 else nn.Identity()\n\n        hidden = max(1, dim // se_reduction)\n        self.se_fc1 = nn.Linear(dim, hidden)\n        self.se_act = nn.GELU()\n        self.se_fc2 = nn.Linear(hidden, dim)\n        self.se_sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        shortcut = x\n        x = self.dwconv(x)\n        x = x.permute(0, 2, 3, 1)  # (N,H,W,C)\n        x = self.norm(x)\n        N, H, W, C = x.shape\n        x_flat = x.reshape(-1, C)\n        x_flat = self.kan1(x_flat)\n        x = x_flat.reshape(N, H, W, 4 * C)\n        x = self.act(x)\n        x = self.grn(x)\n        x_flat2 = x.reshape(-1, 4 * C)\n        x_flat2 = self.kan2(x_flat2)\n        x = x_flat2.reshape(N, H, W, C)\n\n        se = x.mean(dim=(1, 2))              # (N, C)\n        se = self.se_fc1(se)\n        se = self.se_act(se)\n        se = self.se_fc2(se)\n        se = self.se_sigmoid(se).unsqueeze(1).unsqueeze(1)\n        x = x * se\n\n        x = x.permute(0, 3, 1, 2)\n        x = shortcut + self.drop_path(x)\n        return x\n\n# -------------------- ConvNeXtV2 backbone builder --------------------\n\nclass ConvNeXtV2Backbone(nn.Module):\n    def __init__(self, in_chans=3, num_classes=1000, block_cls=ConvNeXtBlockBaseline, depths=[3,3,9,3], dims=[96,192,384,768], drop_path_rate=0.0, head_init_scale=1.0):\n        super().__init__()\n        self.depths = depths\n        self.downsample_layers = nn.ModuleList()\n        stem = nn.Sequential(\n            nn.Conv2d(in_chans, dims[0], kernel_size=4, stride=4),\n            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\"),\n        )\n        self.downsample_layers.append(stem)\n        for i in range(3):\n            down = nn.Sequential(\n                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n                nn.Conv2d(dims[i], dims[i+1], kernel_size=2, stride=2),\n            )\n            self.downsample_layers.append(down)\n\n        self.stages = nn.ModuleList()\n        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n        cur = 0\n        for i in range(4):\n            blocks = []\n            for j in range(depths[i]):\n                blocks.append(block_cls(dim=dims[i], drop_path=dp_rates[cur + j]))\n            self.stages.append(nn.Sequential(*blocks))\n            cur += depths[i]\n\n        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)\n        self.head = nn.Linear(dims[-1], num_classes)\n\n        self.apply(self._init_weights)\n        self.head.weight.data.mul_(head_init_scale)\n        self.head.bias.data.mul_(head_init_scale)\n\n    def _init_weights(self, m):\n        if isinstance(m, (nn.Conv2d, nn.Linear)):\n            trunc_normal_(m.weight, std=0.02)\n            if getattr(m, \"bias\", None) is not None:\n                nn.init.constant_(m.bias, 0)\n\n    def forward_features(self, x):\n        for i in range(4):\n            x = self.downsample_layers[i](x)\n            x = self.stages[i](x)\n        x = x.mean([-2, -1])   # global average pooling -> (N, C)\n        x = self.norm(x)\n        return x\n\n    def forward(self, x):\n        x = self.forward_features(x)\n        x = self.head(x)\n        return x\n\n# -------------------- Training & evaluation helpers --------------------\n\ndef compute_metrics_from_logits(logits, targets):\n    preds = logits.argmax(dim=1)\n    acc = (preds == targets).float().mean().item()\n    prec = precision_score(targets.cpu().numpy(), preds.cpu().numpy(), average='macro', zero_division=0)\n    rec  = recall_score(targets.cpu().numpy(), preds.cpu().numpy(), average='macro', zero_division=0)\n    f1   = f1_score(targets.cpu().numpy(), preds.cpu().numpy(), average='macro', zero_division=0)\n    return acc, prec, rec, f1, preds.cpu().numpy()\n\ndef train_one_epoch(model, loader, criterion, optimizer, device, kan_reg_weight=0.0):\n    model.train()\n    running_loss = 0.0\n    all_logits = []; all_targets = []\n    for imgs, labels in loader:\n        imgs = imgs.to(device); labels = labels.to(device, dtype=torch.long)\n        optimizer.zero_grad()\n        logits = model(imgs)\n        loss = criterion(logits, labels)\n        # optional: include KAN regularization if present\n        if kan_reg_weight and hasattr(model, 'modules'):\n            reg = 0.0\n            for m in model.modules():\n                if hasattr(m, 'regularization_loss'):\n                    reg = reg + m.regularization_loss()\n            if isinstance(reg, torch.Tensor):\n                loss = loss + kan_reg_weight * reg\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * imgs.size(0)\n        all_logits.append(logits.detach().cpu()); all_targets.append(labels.detach().cpu())\n    epoch_loss = running_loss / max(1, len(loader.dataset))\n    all_logits = torch.cat(all_logits) if len(all_logits)>0 else torch.tensor([])\n    all_targets = torch.cat(all_targets) if len(all_targets)>0 else torch.tensor([])\n    if all_logits.numel() == 0:\n        return epoch_loss, 0., 0., 0., 0.\n    acc, prec, rec, f1, _ = compute_metrics_from_logits(all_logits, all_targets)\n    return epoch_loss, acc, prec, rec, f1\n\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    all_logits = []; all_targets = []\n    with torch.no_grad():\n        for imgs, labels in loader:\n            imgs = imgs.to(device); labels = labels.to(device, dtype=torch.long)\n            logits = model(imgs)\n            loss = criterion(logits, labels)\n            running_loss += loss.item() * imgs.size(0)\n            all_logits.append(logits.cpu()); all_targets.append(labels.cpu())\n    n = max(1, len(loader.dataset))\n    val_loss = running_loss / n\n    all_logits = torch.cat(all_logits) if len(all_logits)>0 else torch.tensor([])\n    all_targets = torch.cat(all_targets) if len(all_targets)>0 else torch.tensor([])\n    if all_logits.numel() == 0:\n        return val_loss, 0., 0., 0., 0., all_logits, all_targets, np.array([])\n    acc, prec, rec, f1, preds = compute_metrics_from_logits(all_logits, all_targets)\n    return val_loss, acc, prec, rec, f1, all_logits, all_targets, preds\n\ndef run_experiment(name, block_cls, depths, dims, seed, dataloaders, device,\n                   epochs=10, lr=2e-4, weight_decay=1e-4, drop_path_rate=0.1, kan_reg_weight=0.0, outdir='results'):\n    ensure_dir(outdir)\n    set_global_seed(seed)\n    num_classes = dataloaders['meta']['num_classes']\n    model = ConvNeXtV2Backbone(in_chans=3, num_classes=num_classes, block_cls=block_cls,\n                               depths=depths, dims=dims, drop_path_rate=drop_path_rate).to(device)\n    print(f\"[{name}] params: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n    criterion = nn.CrossEntropyLoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=False)\n    best_val_acc = -1.0\n    history = {'epoch':[], 'train_loss':[], 'train_acc':[], 'train_prec':[], 'train_rec':[], 'train_f1':[],\n               'val_loss':[], 'val_acc':[], 'val_prec':[], 'val_rec':[], 'val_f1':[]}\n    for epoch in range(1, epochs+1):\n        train_loss, train_acc, train_prec, train_rec, train_f1 = train_one_epoch(model, dataloaders['train'], criterion, optimizer, device, kan_reg_weight=kan_reg_weight)\n        val_loss, val_acc, val_prec, val_rec, val_f1, _, _, _ = evaluate(model, dataloaders['val'], criterion, device)\n        scheduler.step(val_loss)\n        history['epoch'].append(epoch); history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n        history['train_prec'].append(train_prec); history['train_rec'].append(train_rec); history['train_f1'].append(train_f1)\n        history['val_loss'].append(val_loss); history['val_acc'].append(val_acc); history['val_prec'].append(val_prec); history['val_rec'].append(val_rec); history['val_f1'].append(val_f1)\n        print(f\"[{name}] Epoch {epoch}/{epochs} train_loss {train_loss:.4f} val_loss {val_loss:.4f} train_acc {train_acc:.4f} val_acc {val_acc:.4f}\")\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict(), 'val_acc': val_acc}, os.path.join(outdir, f\"best_{name}.pth\"))\n            print(f\"[{name}] saved best checkpoint (val_acc={val_acc:.4f})\")\n    # load best for test\n    best_path = os.path.join(outdir, f\"best_{name}.pth\")\n    if os.path.exists(best_path):\n        ckpt = torch.load(best_path, map_location=device)\n        model.load_state_dict(ckpt['state_dict'])\n    test_loss, test_acc, test_prec, test_rec, test_f1, logits, targets, preds = evaluate(model, dataloaders['test'], criterion, device)\n    # save artifacts\n    hist_df = pd.DataFrame(history); hist_df.to_csv(os.path.join(outdir, f\"history_{name}.csv\"), index=False)\n    # curves\n    try:\n        plt.figure(figsize=(10,4))\n        plt.subplot(1,2,1); plt.plot(history['epoch'], history['train_loss'], label='train'); plt.plot(history['epoch'], history['val_loss'], label='val'); plt.legend(); plt.title(f\"{name} Loss\")\n        plt.subplot(1,2,2); plt.plot(history['epoch'], history['train_acc'], label='train'); plt.plot(history['epoch'], history['val_acc'], label='val'); plt.legend(); plt.title(f\"{name} Acc\")\n        plt.tight_layout(); plt.savefig(os.path.join(outdir, f\"{name}_curves.png\")); plt.close()\n    except Exception:\n        pass\n    # confusion matrix & report\n    if isinstance(preds, np.ndarray) and preds.size>0:\n        cm = confusion_matrix(targets.numpy(), preds)\n        try:\n            plt.figure(figsize=(6,6)); plt.imshow(cm, interpolation='nearest'); plt.title(f'CM {name}'); plt.colorbar()\n            ticks = np.arange(len(dataloaders['meta']['classes'])); plt.xticks(ticks, dataloaders['meta']['classes'], rotation=45); plt.yticks(ticks, dataloaders['meta']['classes']); plt.tight_layout()\n            plt.savefig(os.path.join(outdir, f\"{name}_confusion.png\")); plt.close()\n        except Exception:\n            pass\n        rpt = classification_report(targets.numpy(), preds, target_names=dataloaders['meta']['classes'], zero_division=0)\n    else:\n        rpt = \"No predictions to compute report.\"\n    with open(os.path.join(outdir, f\"{name}_report.txt\"), 'w') as f:\n        f.write(f\"Test loss: {test_loss:.4f}\\nTest acc: {test_acc:.4f}\\nPrec: {test_prec:.4f}\\nRec: {test_rec:.4f}\\nF1: {test_f1:.4f}\\n\\n\")\n        f.write(\"Classification report:\\n\"); f.write(str(rpt))\n    print(f\"[{name}] TEST -> loss {test_loss:.4f} acc {test_acc:.4f} prec {test_prec:.4f} rec {test_rec:.4f} f1 {test_f1:.4f}\")\n    return {'name': name, 'history': history, 'test_loss': test_loss, 'test_acc': test_acc, 'test_prec': test_prec, 'test_rec': test_rec, 'test_f1': test_f1}\n\n# -------------------- Main experiment entrypoint --------------------\n\nif __name__ == '__main__':\n    # USER CONFIG - change as needed\n    DATA_ROOT = '/kaggle/input/brain-tumor-mri-dataset'   # expects Training/ and Testing/ subfolders with class subfolders\n    TRAIN_DIR = os.path.join(DATA_ROOT, 'Training')\n    TEST_DIR  = os.path.join(DATA_ROOT, 'Testing')\n    OUTDIR = 'results_compare_fixed'\n    ensure_dir(OUTDIR)\n\n    IMG_SIZE = 160    # set to 160 for very fast debugging, 299/384 for real runs\n    BATCH_SIZE = 64\n    EPOCHS = 100\n    LR = 2e-4\n    WEIGHT_DECAY = 1e-4\n    NUM_WORKERS = 4\n    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    GLOBAL_SEED = 42\n    set_global_seed(GLOBAL_SEED)\n\n    # load dataframes\n    tr_df = get_class_paths(TRAIN_DIR)\n    ts_df = get_class_paths(TEST_DIR) if os.path.isdir(TEST_DIR) else pd.DataFrame(columns=['path','label'])\n    if len(ts_df) == 0:\n        if len(tr_df) == 0:\n            raise RuntimeError(f\"No data found in {TRAIN_DIR} nor {TEST_DIR}. Please check your DATA_ROOT.\")\n        train_df_all, ts_df = safe_train_test_split(tr_df, test_size=0.15, stratify=tr_df['label'] if len(tr_df)>0 else None, random_state=GLOBAL_SEED)\n        tr_df = train_df_all\n    if len(ts_df) == 0:\n        tr_df, ts_df = safe_train_test_split(tr_df, test_size=0.15, stratify=tr_df['label'], random_state=GLOBAL_SEED)\n    valid_df, test_df = safe_train_test_split(ts_df, train_size=0.5, stratify=ts_df['label'] if len(ts_df)>0 else None, random_state=GLOBAL_SEED)\n\n    combined = pd.concat([tr_df, valid_df, test_df], ignore_index=True)\n    classes = sorted(combined['label'].unique().tolist())\n    if len(classes) == 0:\n        raise RuntimeError(\"No classes detected in the data. Please ensure dataset structure is /<class>/*.jpg.\")\n    label2idx = {c:i for i,c in enumerate(classes)}\n    num_classes = len(classes)\n\n    print(\"Classes:\", classes)\n    print(f\"Train samples: {len(tr_df)} | Val samples: {len(valid_df)} | Test samples: {len(test_df)}\")\n\n    # transforms\n    train_tfms = T.Compose([\n        T.RandomResizedCrop(IMG_SIZE, scale=(0.8,1.0)),\n        T.RandomHorizontalFlip(),\n        T.RandomRotation(15),\n        T.ColorJitter(brightness=0.1, contrast=0.1),\n        T.ToTensor(),\n        T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])\n    ])\n    val_tfms = T.Compose([T.Resize((IMG_SIZE,IMG_SIZE)), T.ToTensor(), T.Normalize([0.5]*3,[0.5]*3)])\n\n    # datasets & dataloaders\n    train_dataset = MRIDataset(tr_df, label2idx, transforms=train_tfms)\n    val_dataset   = MRIDataset(valid_df, label2idx, transforms=val_tfms)\n    test_dataset  = MRIDataset(test_df, label2idx, transforms=val_tfms)\n\n    set_global_seed(GLOBAL_SEED)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n    val_loader   = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n    test_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n\n    dataloaders = {'train': train_loader, 'val': val_loader, 'test': test_loader, 'meta': {'num_classes': num_classes, 'classes': classes}}\n\n    # model config\n    depths = (2,2,6,2)           # smaller\n    dims  = (48,96,192,384)      # much smaller channels\n    dp = 0.1\n\n    from functools import partial\n\n    variants = [\n         ('convnextv2_se_kan', partial(ConvNeXtBlockSEKAN, kan_grid_size=3, kan_spline_order=2)),\n        ('convnextv2_kan', partial(ConvNeXtBlockKAN, kan_grid_size=3, kan_spline_order=2)),\n       \n        ('convnextv2_baseline', ConvNeXtBlockBaseline),\n        ('convnextv2_se', ConvNeXtBlockSE),\n        \n    ]\n\n\n    results = []\n    for name, block_cls in variants:\n        print(\"\\n\" + \"=\"*80)\n        print(\"Running:\", name)\n        set_global_seed(GLOBAL_SEED)\n        res = run_experiment(name=name, block_cls=block_cls, depths=depths, dims=dims, seed=GLOBAL_SEED, dataloaders=dataloaders, device=DEVICE, epochs=EPOCHS, lr=LR, weight_decay=WEIGHT_DECAY, drop_path_rate=dp, kan_reg_weight=0.0, outdir=OUTDIR)\n        results.append(res)\n\n    # summary\n    summary_rows = []\n    for r in results:\n        summary_rows.append({'model': r['name'], 'test_loss': r['test_loss'], 'test_acc': r['test_acc'], 'test_prec': r['test_prec'], 'test_rec': r['test_rec'], 'test_f1': r['test_f1']})\n    summary_df = pd.DataFrame(summary_rows)\n    summary_df.to_csv(os.path.join(OUTDIR, 'summary_results.csv'), index=False)\n    print(\"\\nSummary results:\")\n    print(summary_df.to_string(index=False))\n    print(\"All outputs saved to:\", OUTDIR)\n\n# End of script\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-20T10:59:21.644147Z","iopub.execute_input":"2025-10-20T10:59:21.644771Z","iopub.status.idle":"2025-10-20T16:24:40.591328Z","shell.execute_reply.started":"2025-10-20T10:59:21.644747Z","shell.execute_reply":"2025-10-20T16:24:40.590477Z"}},"outputs":[{"name":"stdout","text":"Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\nTrain samples: 5712 | Val samples: 655 | Test samples: 656\n\n================================================================================\nRunning: convnextv2_se_kan\n[convnextv2_se_kan] params: 30,989,596\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[convnextv2_se_kan] Epoch 1/100 train_loss 1.2349 val_loss 1.2080 train_acc 0.4149 val_acc 0.4305\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.4305)\n[convnextv2_se_kan] Epoch 2/100 train_loss 0.9547 val_loss 0.9393 train_acc 0.6063 val_acc 0.6351\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.6351)\n[convnextv2_se_kan] Epoch 3/100 train_loss 0.7745 val_loss 0.7600 train_acc 0.6861 val_acc 0.7008\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.7008)\n[convnextv2_se_kan] Epoch 4/100 train_loss 0.6484 val_loss 0.7079 train_acc 0.7295 val_acc 0.7191\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.7191)\n[convnextv2_se_kan] Epoch 5/100 train_loss 0.5624 val_loss 0.6318 train_acc 0.7780 val_acc 0.7557\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.7557)\n[convnextv2_se_kan] Epoch 6/100 train_loss 0.4977 val_loss 0.6109 train_acc 0.8004 val_acc 0.7603\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.7603)\n[convnextv2_se_kan] Epoch 7/100 train_loss 0.4908 val_loss 0.4738 train_acc 0.8027 val_acc 0.8198\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.8198)\n[convnextv2_se_kan] Epoch 8/100 train_loss 0.4487 val_loss 0.4913 train_acc 0.8223 val_acc 0.8000\n[convnextv2_se_kan] Epoch 9/100 train_loss 0.4069 val_loss 0.5177 train_acc 0.8430 val_acc 0.8214\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.8214)\n[convnextv2_se_kan] Epoch 10/100 train_loss 0.3850 val_loss 0.4525 train_acc 0.8531 val_acc 0.8458\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.8458)\n[convnextv2_se_kan] Epoch 11/100 train_loss 0.3457 val_loss 0.4699 train_acc 0.8697 val_acc 0.8336\n[convnextv2_se_kan] Epoch 12/100 train_loss 0.3282 val_loss 0.4244 train_acc 0.8794 val_acc 0.8565\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.8565)\n[convnextv2_se_kan] Epoch 13/100 train_loss 0.3068 val_loss 0.3727 train_acc 0.8887 val_acc 0.8519\n[convnextv2_se_kan] Epoch 14/100 train_loss 0.2814 val_loss 0.3100 train_acc 0.8941 val_acc 0.8992\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.8992)\n[convnextv2_se_kan] Epoch 15/100 train_loss 0.2671 val_loss 0.2690 train_acc 0.9006 val_acc 0.9069\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9069)\n[convnextv2_se_kan] Epoch 16/100 train_loss 0.2622 val_loss 0.2805 train_acc 0.9041 val_acc 0.9023\n[convnextv2_se_kan] Epoch 17/100 train_loss 0.2379 val_loss 0.2730 train_acc 0.9119 val_acc 0.9145\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9145)\n[convnextv2_se_kan] Epoch 18/100 train_loss 0.2384 val_loss 0.3217 train_acc 0.9091 val_acc 0.8962\n[convnextv2_se_kan] Epoch 19/100 train_loss 0.2281 val_loss 0.2892 train_acc 0.9160 val_acc 0.8977\n[convnextv2_se_kan] Epoch 20/100 train_loss 0.2002 val_loss 0.2199 train_acc 0.9273 val_acc 0.9191\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9191)\n[convnextv2_se_kan] Epoch 21/100 train_loss 0.1855 val_loss 0.2168 train_acc 0.9294 val_acc 0.9221\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9221)\n[convnextv2_se_kan] Epoch 22/100 train_loss 0.1637 val_loss 0.2032 train_acc 0.9407 val_acc 0.9267\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9267)\n[convnextv2_se_kan] Epoch 23/100 train_loss 0.1580 val_loss 0.2269 train_acc 0.9443 val_acc 0.9221\n[convnextv2_se_kan] Epoch 24/100 train_loss 0.1633 val_loss 0.2453 train_acc 0.9400 val_acc 0.9115\n[convnextv2_se_kan] Epoch 25/100 train_loss 0.1507 val_loss 0.2392 train_acc 0.9447 val_acc 0.9191\n[convnextv2_se_kan] Epoch 26/100 train_loss 0.1450 val_loss 0.2103 train_acc 0.9480 val_acc 0.9282\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9282)\n[convnextv2_se_kan] Epoch 27/100 train_loss 0.1343 val_loss 0.1946 train_acc 0.9494 val_acc 0.9405\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9405)\n[convnextv2_se_kan] Epoch 28/100 train_loss 0.1151 val_loss 0.1889 train_acc 0.9562 val_acc 0.9374\n[convnextv2_se_kan] Epoch 29/100 train_loss 0.1248 val_loss 0.1756 train_acc 0.9540 val_acc 0.9405\n[convnextv2_se_kan] Epoch 30/100 train_loss 0.1169 val_loss 0.1732 train_acc 0.9582 val_acc 0.9359\n[convnextv2_se_kan] Epoch 31/100 train_loss 0.1176 val_loss 0.1635 train_acc 0.9568 val_acc 0.9389\n[convnextv2_se_kan] Epoch 32/100 train_loss 0.1104 val_loss 0.1597 train_acc 0.9606 val_acc 0.9405\n[convnextv2_se_kan] Epoch 33/100 train_loss 0.1005 val_loss 0.1741 train_acc 0.9652 val_acc 0.9450\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9450)\n[convnextv2_se_kan] Epoch 34/100 train_loss 0.1091 val_loss 0.1781 train_acc 0.9611 val_acc 0.9496\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9496)\n[convnextv2_se_kan] Epoch 35/100 train_loss 0.0999 val_loss 0.1683 train_acc 0.9638 val_acc 0.9405\n[convnextv2_se_kan] Epoch 36/100 train_loss 0.1002 val_loss 0.1660 train_acc 0.9639 val_acc 0.9450\n[convnextv2_se_kan] Epoch 37/100 train_loss 0.0878 val_loss 0.1493 train_acc 0.9699 val_acc 0.9450\n[convnextv2_se_kan] Epoch 38/100 train_loss 0.0870 val_loss 0.1429 train_acc 0.9692 val_acc 0.9527\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9527)\n[convnextv2_se_kan] Epoch 39/100 train_loss 0.0918 val_loss 0.1791 train_acc 0.9657 val_acc 0.9344\n[convnextv2_se_kan] Epoch 40/100 train_loss 0.0901 val_loss 0.1525 train_acc 0.9676 val_acc 0.9573\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9573)\n[convnextv2_se_kan] Epoch 41/100 train_loss 0.0860 val_loss 0.1703 train_acc 0.9706 val_acc 0.9420\n[convnextv2_se_kan] Epoch 42/100 train_loss 0.0865 val_loss 0.1552 train_acc 0.9697 val_acc 0.9420\n[convnextv2_se_kan] Epoch 43/100 train_loss 0.0824 val_loss 0.1502 train_acc 0.9709 val_acc 0.9420\n[convnextv2_se_kan] Epoch 44/100 train_loss 0.0818 val_loss 0.1334 train_acc 0.9715 val_acc 0.9466\n[convnextv2_se_kan] Epoch 45/100 train_loss 0.0774 val_loss 0.1361 train_acc 0.9741 val_acc 0.9466\n[convnextv2_se_kan] Epoch 46/100 train_loss 0.0718 val_loss 0.1306 train_acc 0.9758 val_acc 0.9542\n[convnextv2_se_kan] Epoch 47/100 train_loss 0.0738 val_loss 0.1437 train_acc 0.9732 val_acc 0.9496\n[convnextv2_se_kan] Epoch 48/100 train_loss 0.0816 val_loss 0.1442 train_acc 0.9741 val_acc 0.9481\n[convnextv2_se_kan] Epoch 49/100 train_loss 0.0762 val_loss 0.1344 train_acc 0.9736 val_acc 0.9481\n[convnextv2_se_kan] Epoch 50/100 train_loss 0.0693 val_loss 0.1253 train_acc 0.9760 val_acc 0.9557\n[convnextv2_se_kan] Epoch 51/100 train_loss 0.0749 val_loss 0.1103 train_acc 0.9732 val_acc 0.9649\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9649)\n[convnextv2_se_kan] Epoch 52/100 train_loss 0.0714 val_loss 0.1135 train_acc 0.9755 val_acc 0.9618\n[convnextv2_se_kan] Epoch 53/100 train_loss 0.0667 val_loss 0.1176 train_acc 0.9753 val_acc 0.9557\n[convnextv2_se_kan] Epoch 54/100 train_loss 0.0664 val_loss 0.1226 train_acc 0.9776 val_acc 0.9634\n[convnextv2_se_kan] Epoch 55/100 train_loss 0.0750 val_loss 0.1338 train_acc 0.9746 val_acc 0.9557\n[convnextv2_se_kan] Epoch 56/100 train_loss 0.0669 val_loss 0.1273 train_acc 0.9758 val_acc 0.9603\n[convnextv2_se_kan] Epoch 57/100 train_loss 0.0694 val_loss 0.1340 train_acc 0.9764 val_acc 0.9557\n[convnextv2_se_kan] Epoch 58/100 train_loss 0.0825 val_loss 0.1193 train_acc 0.9725 val_acc 0.9634\n[convnextv2_se_kan] Epoch 59/100 train_loss 0.0696 val_loss 0.1154 train_acc 0.9750 val_acc 0.9634\n[convnextv2_se_kan] Epoch 60/100 train_loss 0.0628 val_loss 0.1114 train_acc 0.9790 val_acc 0.9634\n[convnextv2_se_kan] Epoch 61/100 train_loss 0.0695 val_loss 0.1167 train_acc 0.9757 val_acc 0.9573\n[convnextv2_se_kan] Epoch 62/100 train_loss 0.0646 val_loss 0.1144 train_acc 0.9779 val_acc 0.9618\n[convnextv2_se_kan] Epoch 63/100 train_loss 0.0640 val_loss 0.1166 train_acc 0.9776 val_acc 0.9664\n[convnextv2_se_kan] saved best checkpoint (val_acc=0.9664)\n[convnextv2_se_kan] Epoch 64/100 train_loss 0.0654 val_loss 0.1173 train_acc 0.9767 val_acc 0.9618\n[convnextv2_se_kan] Epoch 65/100 train_loss 0.0593 val_loss 0.1139 train_acc 0.9795 val_acc 0.9664\n[convnextv2_se_kan] Epoch 66/100 train_loss 0.0682 val_loss 0.1181 train_acc 0.9769 val_acc 0.9618\n[convnextv2_se_kan] Epoch 67/100 train_loss 0.0667 val_loss 0.1141 train_acc 0.9771 val_acc 0.9649\n[convnextv2_se_kan] Epoch 68/100 train_loss 0.0599 val_loss 0.1163 train_acc 0.9813 val_acc 0.9603\n[convnextv2_se_kan] Epoch 69/100 train_loss 0.0626 val_loss 0.1141 train_acc 0.9790 val_acc 0.9603\n[convnextv2_se_kan] Epoch 70/100 train_loss 0.0613 val_loss 0.1139 train_acc 0.9772 val_acc 0.9603\n[convnextv2_se_kan] Epoch 71/100 train_loss 0.0607 val_loss 0.1143 train_acc 0.9786 val_acc 0.9618\n[convnextv2_se_kan] Epoch 72/100 train_loss 0.0570 val_loss 0.1124 train_acc 0.9809 val_acc 0.9618\n[convnextv2_se_kan] Epoch 73/100 train_loss 0.0627 val_loss 0.1120 train_acc 0.9781 val_acc 0.9649\n[convnextv2_se_kan] Epoch 74/100 train_loss 0.0574 val_loss 0.1112 train_acc 0.9811 val_acc 0.9618\n[convnextv2_se_kan] Epoch 75/100 train_loss 0.0665 val_loss 0.1115 train_acc 0.9732 val_acc 0.9618\n[convnextv2_se_kan] Epoch 76/100 train_loss 0.0573 val_loss 0.1119 train_acc 0.9797 val_acc 0.9649\n[convnextv2_se_kan] Epoch 77/100 train_loss 0.0604 val_loss 0.1124 train_acc 0.9785 val_acc 0.9618\n[convnextv2_se_kan] Epoch 78/100 train_loss 0.0661 val_loss 0.1124 train_acc 0.9744 val_acc 0.9618\n[convnextv2_se_kan] Epoch 79/100 train_loss 0.0685 val_loss 0.1132 train_acc 0.9765 val_acc 0.9634\n[convnextv2_se_kan] Epoch 80/100 train_loss 0.0609 val_loss 0.1132 train_acc 0.9776 val_acc 0.9634\n[convnextv2_se_kan] Epoch 81/100 train_loss 0.0630 val_loss 0.1131 train_acc 0.9781 val_acc 0.9634\n[convnextv2_se_kan] Epoch 82/100 train_loss 0.0609 val_loss 0.1130 train_acc 0.9800 val_acc 0.9634\n[convnextv2_se_kan] Epoch 83/100 train_loss 0.0620 val_loss 0.1133 train_acc 0.9778 val_acc 0.9634\n[convnextv2_se_kan] Epoch 84/100 train_loss 0.0619 val_loss 0.1132 train_acc 0.9776 val_acc 0.9634\n[convnextv2_se_kan] Epoch 85/100 train_loss 0.0653 val_loss 0.1133 train_acc 0.9774 val_acc 0.9634\n[convnextv2_se_kan] Epoch 86/100 train_loss 0.0672 val_loss 0.1132 train_acc 0.9769 val_acc 0.9634\n[convnextv2_se_kan] Epoch 87/100 train_loss 0.0652 val_loss 0.1130 train_acc 0.9765 val_acc 0.9634\n[convnextv2_se_kan] Epoch 88/100 train_loss 0.0559 val_loss 0.1130 train_acc 0.9820 val_acc 0.9634\n[convnextv2_se_kan] Epoch 89/100 train_loss 0.0592 val_loss 0.1131 train_acc 0.9786 val_acc 0.9634\n[convnextv2_se_kan] Epoch 90/100 train_loss 0.0544 val_loss 0.1131 train_acc 0.9816 val_acc 0.9634\n[convnextv2_se_kan] Epoch 91/100 train_loss 0.0645 val_loss 0.1131 train_acc 0.9772 val_acc 0.9634\n[convnextv2_se_kan] Epoch 92/100 train_loss 0.0628 val_loss 0.1132 train_acc 0.9799 val_acc 0.9634\n[convnextv2_se_kan] Epoch 93/100 train_loss 0.0625 val_loss 0.1131 train_acc 0.9783 val_acc 0.9634\n[convnextv2_se_kan] Epoch 94/100 train_loss 0.0617 val_loss 0.1131 train_acc 0.9772 val_acc 0.9634\n[convnextv2_se_kan] Epoch 95/100 train_loss 0.0616 val_loss 0.1131 train_acc 0.9792 val_acc 0.9634\n[convnextv2_se_kan] Epoch 96/100 train_loss 0.0610 val_loss 0.1131 train_acc 0.9767 val_acc 0.9634\n[convnextv2_se_kan] Epoch 97/100 train_loss 0.0634 val_loss 0.1131 train_acc 0.9772 val_acc 0.9634\n[convnextv2_se_kan] Epoch 98/100 train_loss 0.0669 val_loss 0.1131 train_acc 0.9769 val_acc 0.9634\n[convnextv2_se_kan] Epoch 99/100 train_loss 0.0628 val_loss 0.1131 train_acc 0.9774 val_acc 0.9634\n[convnextv2_se_kan] Epoch 100/100 train_loss 0.0580 val_loss 0.1131 train_acc 0.9813 val_acc 0.9634\n[convnextv2_se_kan] TEST -> loss 0.0822 acc 0.9741 prec 0.9737 rec 0.9731 f1 0.9732\n\n================================================================================\nRunning: convnextv2_kan\n[convnextv2_kan] params: 30,717,268\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[convnextv2_kan] Epoch 1/100 train_loss 1.2348 val_loss 1.1351 train_acc 0.4125 val_acc 0.5069\n[convnextv2_kan] saved best checkpoint (val_acc=0.5069)\n[convnextv2_kan] Epoch 2/100 train_loss 1.0210 val_loss 0.8837 train_acc 0.5730 val_acc 0.6336\n[convnextv2_kan] saved best checkpoint (val_acc=0.6336)\n[convnextv2_kan] Epoch 3/100 train_loss 0.7927 val_loss 0.8092 train_acc 0.6921 val_acc 0.6550\n[convnextv2_kan] saved best checkpoint (val_acc=0.6550)\n[convnextv2_kan] Epoch 4/100 train_loss 0.6660 val_loss 0.8141 train_acc 0.7274 val_acc 0.6947\n[convnextv2_kan] saved best checkpoint (val_acc=0.6947)\n[convnextv2_kan] Epoch 5/100 train_loss 0.5969 val_loss 0.7139 train_acc 0.7542 val_acc 0.7130\n[convnextv2_kan] saved best checkpoint (val_acc=0.7130)\n[convnextv2_kan] Epoch 6/100 train_loss 0.5679 val_loss 0.6255 train_acc 0.7647 val_acc 0.7374\n[convnextv2_kan] saved best checkpoint (val_acc=0.7374)\n[convnextv2_kan] Epoch 7/100 train_loss 0.5062 val_loss 0.6105 train_acc 0.7948 val_acc 0.7771\n[convnextv2_kan] saved best checkpoint (val_acc=0.7771)\n[convnextv2_kan] Epoch 8/100 train_loss 0.4702 val_loss 0.5908 train_acc 0.8129 val_acc 0.7817\n[convnextv2_kan] saved best checkpoint (val_acc=0.7817)\n[convnextv2_kan] Epoch 9/100 train_loss 0.4301 val_loss 0.5333 train_acc 0.8314 val_acc 0.7756\n[convnextv2_kan] Epoch 10/100 train_loss 0.4105 val_loss 0.4224 train_acc 0.8340 val_acc 0.8397\n[convnextv2_kan] saved best checkpoint (val_acc=0.8397)\n[convnextv2_kan] Epoch 11/100 train_loss 0.3551 val_loss 0.4092 train_acc 0.8641 val_acc 0.8672\n[convnextv2_kan] saved best checkpoint (val_acc=0.8672)\n[convnextv2_kan] Epoch 12/100 train_loss 0.3475 val_loss 0.3892 train_acc 0.8678 val_acc 0.8519\n[convnextv2_kan] Epoch 13/100 train_loss 0.3009 val_loss 0.3449 train_acc 0.8883 val_acc 0.8626\n[convnextv2_kan] Epoch 14/100 train_loss 0.2859 val_loss 0.3389 train_acc 0.8986 val_acc 0.8916\n[convnextv2_kan] saved best checkpoint (val_acc=0.8916)\n[convnextv2_kan] Epoch 15/100 train_loss 0.2644 val_loss 0.3642 train_acc 0.9002 val_acc 0.8763\n[convnextv2_kan] Epoch 16/100 train_loss 0.2439 val_loss 0.3481 train_acc 0.9098 val_acc 0.8809\n[convnextv2_kan] Epoch 17/100 train_loss 0.2449 val_loss 0.3280 train_acc 0.9119 val_acc 0.8870\n[convnextv2_kan] Epoch 18/100 train_loss 0.2136 val_loss 0.2613 train_acc 0.9231 val_acc 0.9237\n[convnextv2_kan] saved best checkpoint (val_acc=0.9237)\n[convnextv2_kan] Epoch 19/100 train_loss 0.2158 val_loss 0.3434 train_acc 0.9191 val_acc 0.8763\n[convnextv2_kan] Epoch 20/100 train_loss 0.2061 val_loss 0.2431 train_acc 0.9293 val_acc 0.9160\n[convnextv2_kan] Epoch 21/100 train_loss 0.1974 val_loss 0.3097 train_acc 0.9291 val_acc 0.8901\n[convnextv2_kan] Epoch 22/100 train_loss 0.1757 val_loss 0.2311 train_acc 0.9333 val_acc 0.9130\n[convnextv2_kan] Epoch 23/100 train_loss 0.1743 val_loss 0.2655 train_acc 0.9391 val_acc 0.9206\n[convnextv2_kan] Epoch 24/100 train_loss 0.1620 val_loss 0.2300 train_acc 0.9426 val_acc 0.9145\n[convnextv2_kan] Epoch 25/100 train_loss 0.1596 val_loss 0.2874 train_acc 0.9414 val_acc 0.9099\n[convnextv2_kan] Epoch 26/100 train_loss 0.1491 val_loss 0.1847 train_acc 0.9484 val_acc 0.9481\n[convnextv2_kan] saved best checkpoint (val_acc=0.9481)\n[convnextv2_kan] Epoch 27/100 train_loss 0.1398 val_loss 0.2035 train_acc 0.9491 val_acc 0.9298\n[convnextv2_kan] Epoch 28/100 train_loss 0.1313 val_loss 0.1606 train_acc 0.9515 val_acc 0.9420\n[convnextv2_kan] Epoch 29/100 train_loss 0.1344 val_loss 0.1321 train_acc 0.9512 val_acc 0.9542\n[convnextv2_kan] saved best checkpoint (val_acc=0.9542)\n[convnextv2_kan] Epoch 30/100 train_loss 0.1167 val_loss 0.1411 train_acc 0.9583 val_acc 0.9496\n[convnextv2_kan] Epoch 31/100 train_loss 0.1151 val_loss 0.1418 train_acc 0.9547 val_acc 0.9557\n[convnextv2_kan] saved best checkpoint (val_acc=0.9557)\n[convnextv2_kan] Epoch 32/100 train_loss 0.1275 val_loss 0.1774 train_acc 0.9550 val_acc 0.9405\n[convnextv2_kan] Epoch 33/100 train_loss 0.1255 val_loss 0.1559 train_acc 0.9541 val_acc 0.9450\n[convnextv2_kan] Epoch 34/100 train_loss 0.0819 val_loss 0.1421 train_acc 0.9737 val_acc 0.9527\n[convnextv2_kan] Epoch 35/100 train_loss 0.0713 val_loss 0.1553 train_acc 0.9751 val_acc 0.9573\n[convnextv2_kan] saved best checkpoint (val_acc=0.9573)\n[convnextv2_kan] Epoch 36/100 train_loss 0.0729 val_loss 0.1075 train_acc 0.9753 val_acc 0.9649\n[convnextv2_kan] saved best checkpoint (val_acc=0.9649)\n[convnextv2_kan] Epoch 37/100 train_loss 0.0659 val_loss 0.1128 train_acc 0.9760 val_acc 0.9588\n[convnextv2_kan] Epoch 38/100 train_loss 0.0772 val_loss 0.1011 train_acc 0.9718 val_acc 0.9695\n[convnextv2_kan] saved best checkpoint (val_acc=0.9695)\n[convnextv2_kan] Epoch 39/100 train_loss 0.0732 val_loss 0.1490 train_acc 0.9730 val_acc 0.9405\n[convnextv2_kan] Epoch 40/100 train_loss 0.0718 val_loss 0.0824 train_acc 0.9757 val_acc 0.9695\n[convnextv2_kan] Epoch 41/100 train_loss 0.0690 val_loss 0.0738 train_acc 0.9748 val_acc 0.9802\n[convnextv2_kan] saved best checkpoint (val_acc=0.9802)\n[convnextv2_kan] Epoch 42/100 train_loss 0.0662 val_loss 0.0851 train_acc 0.9772 val_acc 0.9725\n[convnextv2_kan] Epoch 43/100 train_loss 0.0611 val_loss 0.0606 train_acc 0.9788 val_acc 0.9817\n[convnextv2_kan] saved best checkpoint (val_acc=0.9817)\n[convnextv2_kan] Epoch 44/100 train_loss 0.0630 val_loss 0.0941 train_acc 0.9765 val_acc 0.9710\n[convnextv2_kan] Epoch 45/100 train_loss 0.0648 val_loss 0.0840 train_acc 0.9785 val_acc 0.9756\n[convnextv2_kan] Epoch 46/100 train_loss 0.0609 val_loss 0.0619 train_acc 0.9788 val_acc 0.9786\n[convnextv2_kan] Epoch 47/100 train_loss 0.0549 val_loss 0.0929 train_acc 0.9818 val_acc 0.9771\n[convnextv2_kan] Epoch 48/100 train_loss 0.0474 val_loss 0.1241 train_acc 0.9844 val_acc 0.9634\n[convnextv2_kan] Epoch 49/100 train_loss 0.0415 val_loss 0.0960 train_acc 0.9855 val_acc 0.9695\n[convnextv2_kan] Epoch 50/100 train_loss 0.0411 val_loss 0.0903 train_acc 0.9874 val_acc 0.9756\n[convnextv2_kan] Epoch 51/100 train_loss 0.0320 val_loss 0.1066 train_acc 0.9890 val_acc 0.9710\n[convnextv2_kan] Epoch 52/100 train_loss 0.0396 val_loss 0.0838 train_acc 0.9849 val_acc 0.9756\n[convnextv2_kan] Epoch 53/100 train_loss 0.0332 val_loss 0.0781 train_acc 0.9890 val_acc 0.9771\n[convnextv2_kan] Epoch 54/100 train_loss 0.0343 val_loss 0.0745 train_acc 0.9865 val_acc 0.9740\n[convnextv2_kan] Epoch 55/100 train_loss 0.0320 val_loss 0.0606 train_acc 0.9884 val_acc 0.9847\n[convnextv2_kan] saved best checkpoint (val_acc=0.9847)\n[convnextv2_kan] Epoch 56/100 train_loss 0.0334 val_loss 0.0690 train_acc 0.9877 val_acc 0.9802\n[convnextv2_kan] Epoch 57/100 train_loss 0.0289 val_loss 0.0708 train_acc 0.9905 val_acc 0.9786\n[convnextv2_kan] Epoch 58/100 train_loss 0.0291 val_loss 0.0649 train_acc 0.9905 val_acc 0.9817\n[convnextv2_kan] Epoch 59/100 train_loss 0.0251 val_loss 0.0642 train_acc 0.9923 val_acc 0.9832\n[convnextv2_kan] Epoch 60/100 train_loss 0.0252 val_loss 0.0644 train_acc 0.9909 val_acc 0.9863\n[convnextv2_kan] saved best checkpoint (val_acc=0.9863)\n[convnextv2_kan] Epoch 61/100 train_loss 0.0290 val_loss 0.0623 train_acc 0.9907 val_acc 0.9863\n[convnextv2_kan] Epoch 62/100 train_loss 0.0235 val_loss 0.0629 train_acc 0.9942 val_acc 0.9832\n[convnextv2_kan] Epoch 63/100 train_loss 0.0248 val_loss 0.0549 train_acc 0.9918 val_acc 0.9863\n[convnextv2_kan] Epoch 64/100 train_loss 0.0261 val_loss 0.0540 train_acc 0.9921 val_acc 0.9863\n[convnextv2_kan] Epoch 65/100 train_loss 0.0237 val_loss 0.0588 train_acc 0.9911 val_acc 0.9817\n[convnextv2_kan] Epoch 66/100 train_loss 0.0245 val_loss 0.0588 train_acc 0.9916 val_acc 0.9847\n[convnextv2_kan] Epoch 67/100 train_loss 0.0240 val_loss 0.0654 train_acc 0.9925 val_acc 0.9802\n[convnextv2_kan] Epoch 68/100 train_loss 0.0238 val_loss 0.0600 train_acc 0.9923 val_acc 0.9802\n[convnextv2_kan] Epoch 69/100 train_loss 0.0244 val_loss 0.0567 train_acc 0.9928 val_acc 0.9832\n[convnextv2_kan] Epoch 70/100 train_loss 0.0238 val_loss 0.0545 train_acc 0.9921 val_acc 0.9847\n[convnextv2_kan] Epoch 71/100 train_loss 0.0214 val_loss 0.0536 train_acc 0.9935 val_acc 0.9863\n[convnextv2_kan] Epoch 72/100 train_loss 0.0231 val_loss 0.0590 train_acc 0.9925 val_acc 0.9847\n[convnextv2_kan] Epoch 73/100 train_loss 0.0254 val_loss 0.0585 train_acc 0.9919 val_acc 0.9847\n[convnextv2_kan] Epoch 74/100 train_loss 0.0247 val_loss 0.0571 train_acc 0.9933 val_acc 0.9847\n[convnextv2_kan] Epoch 75/100 train_loss 0.0227 val_loss 0.0570 train_acc 0.9926 val_acc 0.9847\n[convnextv2_kan] Epoch 76/100 train_loss 0.0202 val_loss 0.0588 train_acc 0.9926 val_acc 0.9817\n[convnextv2_kan] Epoch 77/100 train_loss 0.0201 val_loss 0.0594 train_acc 0.9939 val_acc 0.9817\n[convnextv2_kan] Epoch 78/100 train_loss 0.0193 val_loss 0.0567 train_acc 0.9944 val_acc 0.9847\n[convnextv2_kan] Epoch 79/100 train_loss 0.0240 val_loss 0.0561 train_acc 0.9914 val_acc 0.9847\n[convnextv2_kan] Epoch 80/100 train_loss 0.0245 val_loss 0.0573 train_acc 0.9919 val_acc 0.9847\n[convnextv2_kan] Epoch 81/100 train_loss 0.0242 val_loss 0.0560 train_acc 0.9919 val_acc 0.9847\n[convnextv2_kan] Epoch 82/100 train_loss 0.0198 val_loss 0.0554 train_acc 0.9933 val_acc 0.9863\n[convnextv2_kan] Epoch 83/100 train_loss 0.0191 val_loss 0.0561 train_acc 0.9942 val_acc 0.9863\n[convnextv2_kan] Epoch 84/100 train_loss 0.0182 val_loss 0.0561 train_acc 0.9940 val_acc 0.9863\n[convnextv2_kan] Epoch 85/100 train_loss 0.0207 val_loss 0.0556 train_acc 0.9926 val_acc 0.9863\n[convnextv2_kan] Epoch 86/100 train_loss 0.0291 val_loss 0.0552 train_acc 0.9911 val_acc 0.9863\n[convnextv2_kan] Epoch 87/100 train_loss 0.0244 val_loss 0.0556 train_acc 0.9923 val_acc 0.9847\n[convnextv2_kan] Epoch 88/100 train_loss 0.0187 val_loss 0.0554 train_acc 0.9946 val_acc 0.9847\n[convnextv2_kan] Epoch 89/100 train_loss 0.0242 val_loss 0.0556 train_acc 0.9923 val_acc 0.9847\n[convnextv2_kan] Epoch 90/100 train_loss 0.0179 val_loss 0.0556 train_acc 0.9953 val_acc 0.9847\n[convnextv2_kan] Epoch 91/100 train_loss 0.0208 val_loss 0.0551 train_acc 0.9933 val_acc 0.9863\n[convnextv2_kan] Epoch 92/100 train_loss 0.0211 val_loss 0.0550 train_acc 0.9935 val_acc 0.9863\n[convnextv2_kan] Epoch 93/100 train_loss 0.0209 val_loss 0.0550 train_acc 0.9926 val_acc 0.9863\n[convnextv2_kan] Epoch 94/100 train_loss 0.0225 val_loss 0.0549 train_acc 0.9921 val_acc 0.9863\n[convnextv2_kan] Epoch 95/100 train_loss 0.0235 val_loss 0.0547 train_acc 0.9919 val_acc 0.9863\n[convnextv2_kan] Epoch 96/100 train_loss 0.0224 val_loss 0.0548 train_acc 0.9925 val_acc 0.9863\n[convnextv2_kan] Epoch 97/100 train_loss 0.0274 val_loss 0.0549 train_acc 0.9905 val_acc 0.9863\n[convnextv2_kan] Epoch 98/100 train_loss 0.0212 val_loss 0.0548 train_acc 0.9935 val_acc 0.9863\n[convnextv2_kan] Epoch 99/100 train_loss 0.0219 val_loss 0.0549 train_acc 0.9923 val_acc 0.9863\n[convnextv2_kan] Epoch 100/100 train_loss 0.0217 val_loss 0.0549 train_acc 0.9933 val_acc 0.9863\n[convnextv2_kan] TEST -> loss 0.0534 acc 0.9848 prec 0.9845 rec 0.9834 f1 0.9837\n\n================================================================================\nRunning: convnextv2_baseline\n[convnextv2_baseline] params: 4,849,780\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[convnextv2_baseline] Epoch 1/100 train_loss 1.2846 val_loss 1.0384 train_acc 0.3683 val_acc 0.5756\n[convnextv2_baseline] saved best checkpoint (val_acc=0.5756)\n[convnextv2_baseline] Epoch 2/100 train_loss 0.8700 val_loss 0.8399 train_acc 0.6488 val_acc 0.6733\n[convnextv2_baseline] saved best checkpoint (val_acc=0.6733)\n[convnextv2_baseline] Epoch 3/100 train_loss 0.7101 val_loss 0.7390 train_acc 0.7099 val_acc 0.7206\n[convnextv2_baseline] saved best checkpoint (val_acc=0.7206)\n[convnextv2_baseline] Epoch 4/100 train_loss 0.5790 val_loss 0.7141 train_acc 0.7679 val_acc 0.7374\n[convnextv2_baseline] saved best checkpoint (val_acc=0.7374)\n[convnextv2_baseline] Epoch 5/100 train_loss 0.5566 val_loss 0.5889 train_acc 0.7759 val_acc 0.7832\n[convnextv2_baseline] saved best checkpoint (val_acc=0.7832)\n[convnextv2_baseline] Epoch 6/100 train_loss 0.4924 val_loss 0.6177 train_acc 0.8072 val_acc 0.7893\n[convnextv2_baseline] saved best checkpoint (val_acc=0.7893)\n[convnextv2_baseline] Epoch 7/100 train_loss 0.4702 val_loss 0.4747 train_acc 0.8193 val_acc 0.8275\n[convnextv2_baseline] saved best checkpoint (val_acc=0.8275)\n[convnextv2_baseline] Epoch 8/100 train_loss 0.4175 val_loss 0.4989 train_acc 0.8342 val_acc 0.8198\n[convnextv2_baseline] Epoch 9/100 train_loss 0.4074 val_loss 0.4631 train_acc 0.8445 val_acc 0.8214\n[convnextv2_baseline] Epoch 10/100 train_loss 0.3728 val_loss 0.3935 train_acc 0.8563 val_acc 0.8641\n[convnextv2_baseline] saved best checkpoint (val_acc=0.8641)\n[convnextv2_baseline] Epoch 11/100 train_loss 0.3608 val_loss 0.4236 train_acc 0.8673 val_acc 0.8504\n[convnextv2_baseline] Epoch 12/100 train_loss 0.3401 val_loss 0.3813 train_acc 0.8718 val_acc 0.8656\n[convnextv2_baseline] saved best checkpoint (val_acc=0.8656)\n[convnextv2_baseline] Epoch 13/100 train_loss 0.3062 val_loss 0.4525 train_acc 0.8866 val_acc 0.8229\n[convnextv2_baseline] Epoch 14/100 train_loss 0.3022 val_loss 0.2909 train_acc 0.8953 val_acc 0.8992\n[convnextv2_baseline] saved best checkpoint (val_acc=0.8992)\n[convnextv2_baseline] Epoch 15/100 train_loss 0.2962 val_loss 0.3362 train_acc 0.8901 val_acc 0.8855\n[convnextv2_baseline] Epoch 16/100 train_loss 0.2706 val_loss 0.4069 train_acc 0.8978 val_acc 0.8565\n[convnextv2_baseline] Epoch 17/100 train_loss 0.2724 val_loss 0.3154 train_acc 0.8957 val_acc 0.8947\n[convnextv2_baseline] Epoch 18/100 train_loss 0.2488 val_loss 0.2850 train_acc 0.9088 val_acc 0.9099\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9099)\n[convnextv2_baseline] Epoch 19/100 train_loss 0.2395 val_loss 0.3601 train_acc 0.9135 val_acc 0.8824\n[convnextv2_baseline] Epoch 20/100 train_loss 0.2402 val_loss 0.2774 train_acc 0.9119 val_acc 0.9160\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9160)\n[convnextv2_baseline] Epoch 21/100 train_loss 0.2191 val_loss 0.2674 train_acc 0.9209 val_acc 0.9115\n[convnextv2_baseline] Epoch 22/100 train_loss 0.2087 val_loss 0.2550 train_acc 0.9240 val_acc 0.9069\n[convnextv2_baseline] Epoch 23/100 train_loss 0.2080 val_loss 0.2496 train_acc 0.9231 val_acc 0.9099\n[convnextv2_baseline] Epoch 24/100 train_loss 0.2071 val_loss 0.2804 train_acc 0.9231 val_acc 0.9069\n[convnextv2_baseline] Epoch 25/100 train_loss 0.1906 val_loss 0.2144 train_acc 0.9300 val_acc 0.9328\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9328)\n[convnextv2_baseline] Epoch 26/100 train_loss 0.1994 val_loss 0.2757 train_acc 0.9231 val_acc 0.8947\n[convnextv2_baseline] Epoch 27/100 train_loss 0.1902 val_loss 0.2536 train_acc 0.9280 val_acc 0.9191\n[convnextv2_baseline] Epoch 28/100 train_loss 0.1709 val_loss 0.2056 train_acc 0.9377 val_acc 0.9344\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9344)\n[convnextv2_baseline] Epoch 29/100 train_loss 0.1495 val_loss 0.2302 train_acc 0.9473 val_acc 0.9267\n[convnextv2_baseline] Epoch 30/100 train_loss 0.1687 val_loss 0.1891 train_acc 0.9350 val_acc 0.9282\n[convnextv2_baseline] Epoch 31/100 train_loss 0.1666 val_loss 0.1394 train_acc 0.9386 val_acc 0.9603\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9603)\n[convnextv2_baseline] Epoch 32/100 train_loss 0.1507 val_loss 0.2179 train_acc 0.9487 val_acc 0.9252\n[convnextv2_baseline] Epoch 33/100 train_loss 0.1488 val_loss 0.2318 train_acc 0.9480 val_acc 0.9267\n[convnextv2_baseline] Epoch 34/100 train_loss 0.1588 val_loss 0.1617 train_acc 0.9419 val_acc 0.9527\n[convnextv2_baseline] Epoch 35/100 train_loss 0.1442 val_loss 0.1408 train_acc 0.9487 val_acc 0.9466\n[convnextv2_baseline] Epoch 36/100 train_loss 0.1125 val_loss 0.1305 train_acc 0.9590 val_acc 0.9588\n[convnextv2_baseline] Epoch 37/100 train_loss 0.1026 val_loss 0.1355 train_acc 0.9604 val_acc 0.9542\n[convnextv2_baseline] Epoch 38/100 train_loss 0.0976 val_loss 0.1538 train_acc 0.9638 val_acc 0.9466\n[convnextv2_baseline] Epoch 39/100 train_loss 0.1062 val_loss 0.1760 train_acc 0.9625 val_acc 0.9313\n[convnextv2_baseline] Epoch 40/100 train_loss 0.0963 val_loss 0.1285 train_acc 0.9674 val_acc 0.9557\n[convnextv2_baseline] Epoch 41/100 train_loss 0.0989 val_loss 0.1255 train_acc 0.9638 val_acc 0.9588\n[convnextv2_baseline] Epoch 42/100 train_loss 0.0864 val_loss 0.1222 train_acc 0.9676 val_acc 0.9603\n[convnextv2_baseline] Epoch 43/100 train_loss 0.0878 val_loss 0.1398 train_acc 0.9695 val_acc 0.9466\n[convnextv2_baseline] Epoch 44/100 train_loss 0.0881 val_loss 0.1092 train_acc 0.9674 val_acc 0.9649\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9649)\n[convnextv2_baseline] Epoch 45/100 train_loss 0.0868 val_loss 0.1212 train_acc 0.9659 val_acc 0.9618\n[convnextv2_baseline] Epoch 46/100 train_loss 0.0807 val_loss 0.1122 train_acc 0.9730 val_acc 0.9679\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9679)\n[convnextv2_baseline] Epoch 47/100 train_loss 0.0844 val_loss 0.1158 train_acc 0.9706 val_acc 0.9618\n[convnextv2_baseline] Epoch 48/100 train_loss 0.0725 val_loss 0.1324 train_acc 0.9748 val_acc 0.9527\n[convnextv2_baseline] Epoch 49/100 train_loss 0.0734 val_loss 0.1066 train_acc 0.9739 val_acc 0.9695\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9695)\n[convnextv2_baseline] Epoch 50/100 train_loss 0.0563 val_loss 0.1153 train_acc 0.9814 val_acc 0.9664\n[convnextv2_baseline] Epoch 51/100 train_loss 0.0630 val_loss 0.0975 train_acc 0.9790 val_acc 0.9771\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9771)\n[convnextv2_baseline] Epoch 52/100 train_loss 0.0559 val_loss 0.1108 train_acc 0.9797 val_acc 0.9695\n[convnextv2_baseline] Epoch 53/100 train_loss 0.0591 val_loss 0.1196 train_acc 0.9792 val_acc 0.9634\n[convnextv2_baseline] Epoch 54/100 train_loss 0.0541 val_loss 0.1041 train_acc 0.9813 val_acc 0.9664\n[convnextv2_baseline] Epoch 55/100 train_loss 0.0515 val_loss 0.0996 train_acc 0.9842 val_acc 0.9679\n[convnextv2_baseline] Epoch 56/100 train_loss 0.0508 val_loss 0.0814 train_acc 0.9830 val_acc 0.9771\n[convnextv2_baseline] Epoch 57/100 train_loss 0.0527 val_loss 0.0879 train_acc 0.9806 val_acc 0.9786\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9786)\n[convnextv2_baseline] Epoch 58/100 train_loss 0.0480 val_loss 0.0813 train_acc 0.9842 val_acc 0.9786\n[convnextv2_baseline] Epoch 59/100 train_loss 0.0456 val_loss 0.0869 train_acc 0.9837 val_acc 0.9786\n[convnextv2_baseline] Epoch 60/100 train_loss 0.0497 val_loss 0.0894 train_acc 0.9828 val_acc 0.9740\n[convnextv2_baseline] Epoch 61/100 train_loss 0.0470 val_loss 0.0982 train_acc 0.9846 val_acc 0.9740\n[convnextv2_baseline] Epoch 62/100 train_loss 0.0504 val_loss 0.0874 train_acc 0.9827 val_acc 0.9771\n[convnextv2_baseline] Epoch 63/100 train_loss 0.0389 val_loss 0.0865 train_acc 0.9856 val_acc 0.9786\n[convnextv2_baseline] Epoch 64/100 train_loss 0.0354 val_loss 0.0863 train_acc 0.9872 val_acc 0.9786\n[convnextv2_baseline] Epoch 65/100 train_loss 0.0346 val_loss 0.0828 train_acc 0.9893 val_acc 0.9802\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9802)\n[convnextv2_baseline] Epoch 66/100 train_loss 0.0415 val_loss 0.0803 train_acc 0.9839 val_acc 0.9802\n[convnextv2_baseline] Epoch 67/100 train_loss 0.0384 val_loss 0.0763 train_acc 0.9874 val_acc 0.9802\n[convnextv2_baseline] Epoch 68/100 train_loss 0.0378 val_loss 0.0810 train_acc 0.9862 val_acc 0.9771\n[convnextv2_baseline] Epoch 69/100 train_loss 0.0371 val_loss 0.0847 train_acc 0.9862 val_acc 0.9771\n[convnextv2_baseline] Epoch 70/100 train_loss 0.0383 val_loss 0.0914 train_acc 0.9863 val_acc 0.9771\n[convnextv2_baseline] Epoch 71/100 train_loss 0.0335 val_loss 0.0902 train_acc 0.9890 val_acc 0.9786\n[convnextv2_baseline] Epoch 72/100 train_loss 0.0372 val_loss 0.0906 train_acc 0.9879 val_acc 0.9802\n[convnextv2_baseline] Epoch 73/100 train_loss 0.0365 val_loss 0.0884 train_acc 0.9872 val_acc 0.9771\n[convnextv2_baseline] Epoch 74/100 train_loss 0.0337 val_loss 0.0855 train_acc 0.9888 val_acc 0.9786\n[convnextv2_baseline] Epoch 75/100 train_loss 0.0333 val_loss 0.0820 train_acc 0.9876 val_acc 0.9771\n[convnextv2_baseline] Epoch 76/100 train_loss 0.0315 val_loss 0.0834 train_acc 0.9898 val_acc 0.9802\n[convnextv2_baseline] Epoch 77/100 train_loss 0.0323 val_loss 0.0836 train_acc 0.9897 val_acc 0.9786\n[convnextv2_baseline] Epoch 78/100 train_loss 0.0356 val_loss 0.0830 train_acc 0.9874 val_acc 0.9802\n[convnextv2_baseline] Epoch 79/100 train_loss 0.0362 val_loss 0.0817 train_acc 0.9877 val_acc 0.9802\n[convnextv2_baseline] Epoch 80/100 train_loss 0.0291 val_loss 0.0809 train_acc 0.9888 val_acc 0.9802\n[convnextv2_baseline] Epoch 81/100 train_loss 0.0353 val_loss 0.0822 train_acc 0.9884 val_acc 0.9802\n[convnextv2_baseline] Epoch 82/100 train_loss 0.0323 val_loss 0.0833 train_acc 0.9890 val_acc 0.9802\n[convnextv2_baseline] Epoch 83/100 train_loss 0.0358 val_loss 0.0817 train_acc 0.9870 val_acc 0.9786\n[convnextv2_baseline] Epoch 84/100 train_loss 0.0305 val_loss 0.0815 train_acc 0.9897 val_acc 0.9802\n[convnextv2_baseline] Epoch 85/100 train_loss 0.0323 val_loss 0.0813 train_acc 0.9872 val_acc 0.9802\n[convnextv2_baseline] Epoch 86/100 train_loss 0.0384 val_loss 0.0809 train_acc 0.9869 val_acc 0.9786\n[convnextv2_baseline] Epoch 87/100 train_loss 0.0311 val_loss 0.0803 train_acc 0.9897 val_acc 0.9817\n[convnextv2_baseline] saved best checkpoint (val_acc=0.9817)\n[convnextv2_baseline] Epoch 88/100 train_loss 0.0367 val_loss 0.0808 train_acc 0.9877 val_acc 0.9817\n[convnextv2_baseline] Epoch 89/100 train_loss 0.0308 val_loss 0.0808 train_acc 0.9897 val_acc 0.9786\n[convnextv2_baseline] Epoch 90/100 train_loss 0.0293 val_loss 0.0808 train_acc 0.9905 val_acc 0.9786\n[convnextv2_baseline] Epoch 91/100 train_loss 0.0284 val_loss 0.0810 train_acc 0.9891 val_acc 0.9817\n[convnextv2_baseline] Epoch 92/100 train_loss 0.0322 val_loss 0.0814 train_acc 0.9879 val_acc 0.9817\n[convnextv2_baseline] Epoch 93/100 train_loss 0.0288 val_loss 0.0815 train_acc 0.9912 val_acc 0.9817\n[convnextv2_baseline] Epoch 94/100 train_loss 0.0361 val_loss 0.0812 train_acc 0.9877 val_acc 0.9817\n[convnextv2_baseline] Epoch 95/100 train_loss 0.0304 val_loss 0.0814 train_acc 0.9902 val_acc 0.9802\n[convnextv2_baseline] Epoch 96/100 train_loss 0.0356 val_loss 0.0814 train_acc 0.9883 val_acc 0.9802\n[convnextv2_baseline] Epoch 97/100 train_loss 0.0312 val_loss 0.0815 train_acc 0.9891 val_acc 0.9817\n[convnextv2_baseline] Epoch 98/100 train_loss 0.0318 val_loss 0.0815 train_acc 0.9891 val_acc 0.9817\n[convnextv2_baseline] Epoch 99/100 train_loss 0.0291 val_loss 0.0815 train_acc 0.9900 val_acc 0.9817\n[convnextv2_baseline] Epoch 100/100 train_loss 0.0337 val_loss 0.0814 train_acc 0.9886 val_acc 0.9817\n[convnextv2_baseline] TEST -> loss 0.0708 acc 0.9817 prec 0.9816 rec 0.9800 f1 0.9805\n\n================================================================================\nRunning: convnextv2_se\n[convnextv2_se] params: 5,122,108\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"[convnextv2_se] Epoch 1/100 train_loss 1.2593 val_loss 1.1481 train_acc 0.3955 val_acc 0.5069\n[convnextv2_se] saved best checkpoint (val_acc=0.5069)\n[convnextv2_se] Epoch 2/100 train_loss 0.9208 val_loss 0.8074 train_acc 0.6322 val_acc 0.6977\n[convnextv2_se] saved best checkpoint (val_acc=0.6977)\n[convnextv2_se] Epoch 3/100 train_loss 0.6960 val_loss 0.6841 train_acc 0.7215 val_acc 0.7298\n[convnextv2_se] saved best checkpoint (val_acc=0.7298)\n[convnextv2_se] Epoch 4/100 train_loss 0.6063 val_loss 0.6367 train_acc 0.7712 val_acc 0.7176\n[convnextv2_se] Epoch 5/100 train_loss 0.5427 val_loss 0.6103 train_acc 0.7873 val_acc 0.7573\n[convnextv2_se] saved best checkpoint (val_acc=0.7573)\n[convnextv2_se] Epoch 6/100 train_loss 0.4861 val_loss 0.4858 train_acc 0.8118 val_acc 0.8183\n[convnextv2_se] saved best checkpoint (val_acc=0.8183)\n[convnextv2_se] Epoch 7/100 train_loss 0.4476 val_loss 0.5307 train_acc 0.8207 val_acc 0.8214\n[convnextv2_se] saved best checkpoint (val_acc=0.8214)\n[convnextv2_se] Epoch 8/100 train_loss 0.4166 val_loss 0.4470 train_acc 0.8403 val_acc 0.8351\n[convnextv2_se] saved best checkpoint (val_acc=0.8351)\n[convnextv2_se] Epoch 9/100 train_loss 0.3708 val_loss 0.4508 train_acc 0.8592 val_acc 0.8366\n[convnextv2_se] saved best checkpoint (val_acc=0.8366)\n[convnextv2_se] Epoch 10/100 train_loss 0.3570 val_loss 0.3812 train_acc 0.8673 val_acc 0.8641\n[convnextv2_se] saved best checkpoint (val_acc=0.8641)\n[convnextv2_se] Epoch 11/100 train_loss 0.3491 val_loss 0.3919 train_acc 0.8680 val_acc 0.8748\n[convnextv2_se] saved best checkpoint (val_acc=0.8748)\n[convnextv2_se] Epoch 12/100 train_loss 0.3466 val_loss 0.3499 train_acc 0.8666 val_acc 0.8763\n[convnextv2_se] saved best checkpoint (val_acc=0.8763)\n[convnextv2_se] Epoch 13/100 train_loss 0.3254 val_loss 0.4120 train_acc 0.8764 val_acc 0.8550\n[convnextv2_se] Epoch 14/100 train_loss 0.3187 val_loss 0.3703 train_acc 0.8796 val_acc 0.8656\n[convnextv2_se] Epoch 15/100 train_loss 0.2827 val_loss 0.3518 train_acc 0.8878 val_acc 0.8794\n[convnextv2_se] saved best checkpoint (val_acc=0.8794)\n[convnextv2_se] Epoch 16/100 train_loss 0.2861 val_loss 0.3703 train_acc 0.8923 val_acc 0.8580\n[convnextv2_se] Epoch 17/100 train_loss 0.2414 val_loss 0.3226 train_acc 0.9091 val_acc 0.8916\n[convnextv2_se] saved best checkpoint (val_acc=0.8916)\n[convnextv2_se] Epoch 18/100 train_loss 0.2208 val_loss 0.2504 train_acc 0.9156 val_acc 0.9099\n[convnextv2_se] saved best checkpoint (val_acc=0.9099)\n[convnextv2_se] Epoch 19/100 train_loss 0.2199 val_loss 0.2535 train_acc 0.9209 val_acc 0.9099\n[convnextv2_se] Epoch 20/100 train_loss 0.2152 val_loss 0.2728 train_acc 0.9245 val_acc 0.9053\n[convnextv2_se] Epoch 21/100 train_loss 0.1976 val_loss 0.2446 train_acc 0.9270 val_acc 0.9115\n[convnextv2_se] saved best checkpoint (val_acc=0.9115)\n[convnextv2_se] Epoch 22/100 train_loss 0.1970 val_loss 0.2428 train_acc 0.9277 val_acc 0.9237\n[convnextv2_se] saved best checkpoint (val_acc=0.9237)\n[convnextv2_se] Epoch 23/100 train_loss 0.1888 val_loss 0.2482 train_acc 0.9300 val_acc 0.9176\n[convnextv2_se] Epoch 24/100 train_loss 0.1839 val_loss 0.2233 train_acc 0.9356 val_acc 0.9221\n[convnextv2_se] Epoch 25/100 train_loss 0.1891 val_loss 0.2228 train_acc 0.9310 val_acc 0.9267\n[convnextv2_se] saved best checkpoint (val_acc=0.9267)\n[convnextv2_se] Epoch 26/100 train_loss 0.1845 val_loss 0.1966 train_acc 0.9329 val_acc 0.9344\n[convnextv2_se] saved best checkpoint (val_acc=0.9344)\n[convnextv2_se] Epoch 27/100 train_loss 0.1828 val_loss 0.2498 train_acc 0.9363 val_acc 0.9084\n[convnextv2_se] Epoch 28/100 train_loss 0.1535 val_loss 0.1777 train_acc 0.9443 val_acc 0.9389\n[convnextv2_se] saved best checkpoint (val_acc=0.9389)\n[convnextv2_se] Epoch 29/100 train_loss 0.1828 val_loss 0.2079 train_acc 0.9305 val_acc 0.9328\n[convnextv2_se] Epoch 30/100 train_loss 0.1629 val_loss 0.1888 train_acc 0.9394 val_acc 0.9267\n[convnextv2_se] Epoch 31/100 train_loss 0.1626 val_loss 0.1825 train_acc 0.9424 val_acc 0.9298\n[convnextv2_se] Epoch 32/100 train_loss 0.1594 val_loss 0.1915 train_acc 0.9387 val_acc 0.9313\n[convnextv2_se] Epoch 33/100 train_loss 0.1408 val_loss 0.1425 train_acc 0.9505 val_acc 0.9481\n[convnextv2_se] saved best checkpoint (val_acc=0.9481)\n[convnextv2_se] Epoch 34/100 train_loss 0.1287 val_loss 0.1750 train_acc 0.9527 val_acc 0.9420\n[convnextv2_se] Epoch 35/100 train_loss 0.1292 val_loss 0.1316 train_acc 0.9559 val_acc 0.9557\n[convnextv2_se] saved best checkpoint (val_acc=0.9557)\n[convnextv2_se] Epoch 36/100 train_loss 0.1129 val_loss 0.1404 train_acc 0.9587 val_acc 0.9573\n[convnextv2_se] saved best checkpoint (val_acc=0.9573)\n[convnextv2_se] Epoch 37/100 train_loss 0.1296 val_loss 0.1281 train_acc 0.9508 val_acc 0.9466\n[convnextv2_se] Epoch 38/100 train_loss 0.1209 val_loss 0.1332 train_acc 0.9569 val_acc 0.9511\n[convnextv2_se] Epoch 39/100 train_loss 0.1111 val_loss 0.1264 train_acc 0.9620 val_acc 0.9603\n[convnextv2_se] saved best checkpoint (val_acc=0.9603)\n[convnextv2_se] Epoch 40/100 train_loss 0.1109 val_loss 0.1228 train_acc 0.9620 val_acc 0.9542\n[convnextv2_se] Epoch 41/100 train_loss 0.1165 val_loss 0.1470 train_acc 0.9583 val_acc 0.9435\n[convnextv2_se] Epoch 42/100 train_loss 0.1211 val_loss 0.1179 train_acc 0.9575 val_acc 0.9573\n[convnextv2_se] Epoch 43/100 train_loss 0.1124 val_loss 0.1159 train_acc 0.9615 val_acc 0.9618\n[convnextv2_se] saved best checkpoint (val_acc=0.9618)\n[convnextv2_se] Epoch 44/100 train_loss 0.1064 val_loss 0.1002 train_acc 0.9641 val_acc 0.9649\n[convnextv2_se] saved best checkpoint (val_acc=0.9649)\n[convnextv2_se] Epoch 45/100 train_loss 0.1179 val_loss 0.1167 train_acc 0.9575 val_acc 0.9664\n[convnextv2_se] saved best checkpoint (val_acc=0.9664)\n[convnextv2_se] Epoch 46/100 train_loss 0.0967 val_loss 0.1193 train_acc 0.9667 val_acc 0.9557\n[convnextv2_se] Epoch 47/100 train_loss 0.0969 val_loss 0.1194 train_acc 0.9687 val_acc 0.9634\n[convnextv2_se] Epoch 48/100 train_loss 0.1027 val_loss 0.1289 train_acc 0.9617 val_acc 0.9603\n[convnextv2_se] Epoch 49/100 train_loss 0.0889 val_loss 0.0949 train_acc 0.9676 val_acc 0.9695\n[convnextv2_se] saved best checkpoint (val_acc=0.9695)\n[convnextv2_se] Epoch 50/100 train_loss 0.0923 val_loss 0.0972 train_acc 0.9653 val_acc 0.9695\n[convnextv2_se] Epoch 51/100 train_loss 0.0845 val_loss 0.1263 train_acc 0.9716 val_acc 0.9527\n[convnextv2_se] Epoch 52/100 train_loss 0.0839 val_loss 0.0935 train_acc 0.9688 val_acc 0.9710\n[convnextv2_se] saved best checkpoint (val_acc=0.9710)\n[convnextv2_se] Epoch 53/100 train_loss 0.0819 val_loss 0.1121 train_acc 0.9701 val_acc 0.9557\n[convnextv2_se] Epoch 54/100 train_loss 0.0899 val_loss 0.1086 train_acc 0.9664 val_acc 0.9588\n[convnextv2_se] Epoch 55/100 train_loss 0.0818 val_loss 0.0928 train_acc 0.9702 val_acc 0.9725\n[convnextv2_se] saved best checkpoint (val_acc=0.9725)\n[convnextv2_se] Epoch 56/100 train_loss 0.0812 val_loss 0.0964 train_acc 0.9716 val_acc 0.9710\n[convnextv2_se] Epoch 57/100 train_loss 0.0693 val_loss 0.0898 train_acc 0.9723 val_acc 0.9664\n[convnextv2_se] Epoch 58/100 train_loss 0.0809 val_loss 0.0941 train_acc 0.9695 val_acc 0.9649\n[convnextv2_se] Epoch 59/100 train_loss 0.0793 val_loss 0.0928 train_acc 0.9723 val_acc 0.9664\n[convnextv2_se] Epoch 60/100 train_loss 0.0804 val_loss 0.1106 train_acc 0.9723 val_acc 0.9634\n[convnextv2_se] Epoch 61/100 train_loss 0.0730 val_loss 0.0974 train_acc 0.9765 val_acc 0.9649\n[convnextv2_se] Epoch 62/100 train_loss 0.0663 val_loss 0.0916 train_acc 0.9760 val_acc 0.9740\n[convnextv2_se] saved best checkpoint (val_acc=0.9740)\n[convnextv2_se] Epoch 63/100 train_loss 0.0659 val_loss 0.0837 train_acc 0.9778 val_acc 0.9740\n[convnextv2_se] Epoch 64/100 train_loss 0.0611 val_loss 0.0867 train_acc 0.9783 val_acc 0.9725\n[convnextv2_se] Epoch 65/100 train_loss 0.0609 val_loss 0.0811 train_acc 0.9790 val_acc 0.9740\n[convnextv2_se] Epoch 66/100 train_loss 0.0681 val_loss 0.0906 train_acc 0.9757 val_acc 0.9664\n[convnextv2_se] Epoch 67/100 train_loss 0.0686 val_loss 0.0936 train_acc 0.9753 val_acc 0.9710\n[convnextv2_se] Epoch 68/100 train_loss 0.0619 val_loss 0.0839 train_acc 0.9785 val_acc 0.9771\n[convnextv2_se] saved best checkpoint (val_acc=0.9771)\n[convnextv2_se] Epoch 69/100 train_loss 0.0676 val_loss 0.0753 train_acc 0.9753 val_acc 0.9725\n[convnextv2_se] Epoch 70/100 train_loss 0.0611 val_loss 0.0791 train_acc 0.9771 val_acc 0.9710\n[convnextv2_se] Epoch 71/100 train_loss 0.0626 val_loss 0.0810 train_acc 0.9781 val_acc 0.9710\n[convnextv2_se] Epoch 72/100 train_loss 0.0592 val_loss 0.0877 train_acc 0.9779 val_acc 0.9725\n[convnextv2_se] Epoch 73/100 train_loss 0.0671 val_loss 0.0797 train_acc 0.9771 val_acc 0.9740\n[convnextv2_se] Epoch 74/100 train_loss 0.0628 val_loss 0.0884 train_acc 0.9786 val_acc 0.9679\n[convnextv2_se] Epoch 75/100 train_loss 0.0590 val_loss 0.0767 train_acc 0.9788 val_acc 0.9725\n[convnextv2_se] Epoch 76/100 train_loss 0.0622 val_loss 0.0761 train_acc 0.9799 val_acc 0.9725\n[convnextv2_se] Epoch 77/100 train_loss 0.0577 val_loss 0.0794 train_acc 0.9802 val_acc 0.9710\n[convnextv2_se] Epoch 78/100 train_loss 0.0605 val_loss 0.0739 train_acc 0.9781 val_acc 0.9725\n[convnextv2_se] Epoch 79/100 train_loss 0.0585 val_loss 0.0772 train_acc 0.9779 val_acc 0.9710\n[convnextv2_se] Epoch 80/100 train_loss 0.0610 val_loss 0.0751 train_acc 0.9807 val_acc 0.9740\n[convnextv2_se] Epoch 81/100 train_loss 0.0642 val_loss 0.0752 train_acc 0.9776 val_acc 0.9740\n[convnextv2_se] Epoch 82/100 train_loss 0.0576 val_loss 0.0712 train_acc 0.9795 val_acc 0.9725\n[convnextv2_se] Epoch 83/100 train_loss 0.0596 val_loss 0.0733 train_acc 0.9783 val_acc 0.9710\n[convnextv2_se] Epoch 84/100 train_loss 0.0520 val_loss 0.0742 train_acc 0.9820 val_acc 0.9710\n[convnextv2_se] Epoch 85/100 train_loss 0.0498 val_loss 0.0760 train_acc 0.9816 val_acc 0.9710\n[convnextv2_se] Epoch 86/100 train_loss 0.0588 val_loss 0.0742 train_acc 0.9788 val_acc 0.9740\n[convnextv2_se] Epoch 87/100 train_loss 0.0588 val_loss 0.0748 train_acc 0.9804 val_acc 0.9725\n[convnextv2_se] Epoch 88/100 train_loss 0.0585 val_loss 0.0751 train_acc 0.9820 val_acc 0.9740\n[convnextv2_se] Epoch 89/100 train_loss 0.0595 val_loss 0.0736 train_acc 0.9795 val_acc 0.9740\n[convnextv2_se] Epoch 90/100 train_loss 0.0579 val_loss 0.0722 train_acc 0.9800 val_acc 0.9740\n[convnextv2_se] Epoch 91/100 train_loss 0.0539 val_loss 0.0730 train_acc 0.9788 val_acc 0.9740\n[convnextv2_se] Epoch 92/100 train_loss 0.0582 val_loss 0.0738 train_acc 0.9800 val_acc 0.9740\n[convnextv2_se] Epoch 93/100 train_loss 0.0533 val_loss 0.0738 train_acc 0.9799 val_acc 0.9740\n[convnextv2_se] Epoch 94/100 train_loss 0.0601 val_loss 0.0732 train_acc 0.9786 val_acc 0.9740\n[convnextv2_se] Epoch 95/100 train_loss 0.0575 val_loss 0.0733 train_acc 0.9776 val_acc 0.9740\n[convnextv2_se] Epoch 96/100 train_loss 0.0606 val_loss 0.0735 train_acc 0.9792 val_acc 0.9740\n[convnextv2_se] Epoch 97/100 train_loss 0.0572 val_loss 0.0732 train_acc 0.9795 val_acc 0.9740\n[convnextv2_se] Epoch 98/100 train_loss 0.0496 val_loss 0.0732 train_acc 0.9828 val_acc 0.9740\n[convnextv2_se] Epoch 99/100 train_loss 0.0546 val_loss 0.0736 train_acc 0.9813 val_acc 0.9740\n[convnextv2_se] Epoch 100/100 train_loss 0.0512 val_loss 0.0739 train_acc 0.9832 val_acc 0.9740\n[convnextv2_se] TEST -> loss 0.0824 acc 0.9787 prec 0.9781 rec 0.9772 f1 0.9775\n\nSummary results:\n              model  test_loss  test_acc  test_prec  test_rec  test_f1\n  convnextv2_se_kan   0.082185  0.974085   0.973709  0.973070 0.973245\n     convnextv2_kan   0.053409  0.984756   0.984538  0.983366 0.983717\nconvnextv2_baseline   0.070767  0.981707   0.981618  0.980033 0.980486\n      convnextv2_se   0.082423  0.978659   0.978121  0.977167 0.977484\nAll outputs saved to: results_compare_fixed\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Side-by-side concise comparison — block level and full backbone\n\nNotation: **N** = batch, **C** = channels at that stage, **H,W** = spatial. Shapes shown as `(N,C,H,W)` (channels-first) or `(N,H,W,C)` when channels-last. `pw1` = Linear(C→4C), `pw2` = Linear(4C→C). `KAN1/KAN2` replace `pw1/pw2` when present. `SE` = squeeze-excite gating applied to block output channels.\n\n---\n\n## 1) Block-level flow (rows = step; columns = variant)\n\n| Step | Baseline                                                                                                          | +SE  | +KAN                                                             | +SE + KAN           |\n| ---: | ----------------------------------------------------------------------------------------------------------------- | ---- | ---------------------------------------------------------------- | ------------------- |\n|    0 | Input `x_in` `(N,C,H,W)`                                                                                          | same | same                                                             | same                |\n|    1 | `dwconv 7×7 (groups=C)` → `(N,C,H,W)`                                                                             | same | same                                                             | same                |\n|    2 | `permute` → `(N,H,W,C)`                                                                                           | same | same                                                             | same                |\n|    3 | `LayerNorm (channels_last)` → `(N,H,W,C)`                                                                         | same | same                                                             | same                |\n|    4 | **Projection expand**: `pw1` → `(N,H,W,4C)`                                                                       | same | **KAN1([C→4C])** on flattened `(N*H*W,C)` → reshape `(N,H,W,4C)` | **KAN1**            |\n|    5 | `GELU` → `(N,H,W,4C)`                                                                                             | same | same                                                             | same                |\n|    6 | `GRN` → `(N,H,W,4C)`                                                                                              | same | same                                                             | same                |\n|    7 | **Projection shrink**: `pw2` → `(N,H,W,C)`                                                                        | same | **KAN2([4C→C])** on flattened `(N*H*W,4C)` → reshape `(N,H,W,C)` | **KAN2**            |\n|    8 | *(SE variant only)* `SE`: `global avg (N,C)` → `FC→act→FC→sigmoid` → scale `(N,1,1,C)`; multiply with `(N,H,W,C)` | —    | **(if +SE+KAN)** SE applied here                                 | **SE applied here** |\n|    9 | `permute` → `(N,C,H,W)`                                                                                           | same | same                                                             | same                |\n|   10 | `residual + DropPath` → output `(N,C,H,W)`                                                                        | same | same                                                             | same                |\n\n**Summary:** only differences are (a) whether expand/shrink are Linear vs KAN, and (b) whether SE gating is applied after the second proj and before residual.\n\n---\n\n## 2) Full-backbone flow — stage by stage (generic)\n\n| Stage        | Operation                                                           | Output shape (generic) | Variant differences                                  |\n| ------------ | ------------------------------------------------------------------- | ---------------------: | ---------------------------------------------------- |\n| Input        | image                                                               |          `(N,3,H0,W0)` | —                                                    |\n| Stem         | `Conv2d(3→C0, k=4, s=4)` + `LayerNorm(ch_first)`                    |     `(N,C0,H0/4,W0/4)` | —                                                    |\n| Stage 0      | `depths[0]` × **block** at `C0`                                     |     `(N,C0,H0/4,W0/4)` | blocks use `pw` or `KAN` and optional SE per variant |\n| Downsample 1 | `LayerNorm` + `Conv2d(C0→C1,k=2,s=2)`                               |     `(N,C1,H0/8,W0/8)` | —                                                    |\n| Stage 1      | `depths[1]` × blocks at `C1`                                        |     `(N,C1,H0/8,W0/8)` | as above                                             |\n| Downsample 2 | `LayerNorm` + `Conv2d(C1→C2,k=2,s=2)`                               |   `(N,C2,H0/16,W0/16)` | —                                                    |\n| Stage 2      | `depths[2]` × blocks at `C2`                                        |   `(N,C2,H0/16,W0/16)` | as above                                             |\n| Downsample 3 | `LayerNorm` + `Conv2d(C2→C3,k=2,s=2)`                               |   `(N,C3,H0/32,W0/32)` | —                                                    |\n| Stage 3      | `depths[3]` × blocks at `C3`                                        |   `(N,C3,H0/32,W0/32)` | as above                                             |\n| Head         | `global avg pool → (N,C3)` → `LayerNorm` → `Linear(C3→num_classes)` |      `(N,num_classes)` | —                                                    |\n\n**Where MLP/KAN live:** inside *each* block at every stage at the expand/shrink positions. SE (if used) also inside *each* block after the shrink.\n\n---\n\n## 3) Example numeric trace (your config: `IMG=160`, `dims=(48,96,192,384)`, `depths=(2,2,6,2)`)\n\n* Input `(N,3,160,160)`\n* Stem → `(N,48,40,40)`\n* Stage0 (2 blocks) operate at `(N,48,40,40)`; inside block expand → `(N,192,40,40)`, shrink → `(N,48,40,40)`\n* Downsample → `(N,96,20,20)`\n* Stage1 (2 blocks) operate at `(N,96,20,20)`; expand → `4C=384` etc.\n* Downsample → `(N,192,10,10)`\n* Stage2 (6 blocks) operate at `(N,192,10,10)`; expand → `768`\n* Downsample → `(N,384,5,5)`\n* Stage3 (2 blocks) operate at `(N,384,5,5)`; expand → `1536`\n* Pool → `(N,384)` → head → `(N,num_classes)`\n\n---\n\n## 4) Quick practical notes (1-line each)\n\n* **SE placement**: correct — after `pw2`/`KAN2` and before residual. That’s standard practice.\n* **Why +SE can underperform vs baseline/KAN**: SE applies **global** channel gating which can (a) redundantly suppress KAN’s fine-grained channel structure, (b) introduce optimization conflicts or over-regularization on small datasets. KAN tends to increase expressivity; adding SE may not always help and can sometimes hurt when both interact poorly.\n* **KAN cost**: higher memory/compute (it flattens spatial dims and uses spline bases) — expect slower training and larger GPU use.\n* **If you want best of both**: try lighter SE (larger reduction, weaker gating), or apply SE only in later stages; experiment.\n","metadata":{}},{"cell_type":"markdown","source":"# Quick defs\n\n* **N** = batch size (number of images in batch).\n* **C** = number of channels (feature dimension) at that stage — e.g. 48, 96, 192, 384 in your config.\n* **H, W** = spatial height and width. A tensor shape is written `(N, C, H, W)` (channels-first) or `(N, H, W, C)` (channels-last).\n\n---\n\n# Whole-backbone overview (data path)\n\n1. **Input**: `(N, 3, H0, W0)` — e.g. `(N,3,160,160)`.\n2. **Stem**: `Conv2d(3 -> C0, kernel=4, stride=4)` → spatial downsample by 4: `(N, C0, H0/4, W0/4)`.\n   With your numbers: `(N, 48, 40, 40)`.\n3. **Stage 0**: `depths[0]` blocks at `(N, C0, 40,40)`.\n4. **Downsample** (between stages): `LayerNorm(channels_first) + Conv2d(Ci -> C{i+1}, kernel=2, stride=2)` → halves spatial dims, raises channels.\n\n   * after 1st downsample: `(N, 96, 20,20)`\n   * after 2nd: `(N,192,10,10)`\n   * after 3rd: `(N,384,5,5)`\n5. **Stages 1..3**: each stage runs `depths[i]` blocks at corresponding `(N, C_i, H_i, W_i)`.\n6. **Head**: global average pool over H,W → `(N, C_last)` → `LayerNorm` → `Linear(C_last -> num_classes)` → logits.\n\n---\n\n# Single block — step-by-step (baseline ConvNeXtV2 block)\n\nStart: `x_in (N, C, H, W)`\n\n1. **Depthwise conv 7×7, groups=C**\n   `x = dwconv(x_in)` → `(N, C, H, W)` (spatial same, channels unchanged).\n2. **Permute to channels-last**\n   `x = x.permute(0,2,3,1)` → `(N, H, W, C)`.\n3. **LayerNorm (channels_last)** applied per-channel. Output `(N, H, W, C)`.\n4. **pw1 — pointwise MLP**: `Linear(C → 4·C)` applied independently at each (H,W) location → `(N, H, W, 4C)`.\n\n   * numeric example: if `C=48` then `4C=192`.\n5. **Activation (GELU)** → same shape `(N,H,W,4C)`.\n6. **GRN (Global Response Normalization)** — channel-wise modulation that rescales features using their L2 norms across spatial axes → `(N,H,W,4C)`.\n7. **pw2 — pointwise MLP**: `Linear(4·C → C)` → `(N,H,W,C)`.\n8. **(Optional) SE gating** — *if present* (see variant): compute `se = sigmoid( FC(FC(x_global)) )` with `x_global = x.mean(dim=(1,2))` giving `(N,C)`. Scale `x *= se.unsqueeze(1).unsqueeze(1)` → `(N,H,W,C)`.\n9. **Permute back to channels-first** → `(N, C, H, W)`.\n10. **DropPath (stochastic depth) + residual add**: `out = x_in + DropPath(x)` → `(N, C, H, W)`.\n\n**Where the MLPs are in baseline:** the two `Linear` layers in steps 4 and 7 are the block MLP (inverted: expand then shrink).\n\n---\n\n# KAN vs MLP (where they appear)\n\n* **Baseline / SE variants**: use standard `pw1`/`pw2` (torch `nn.Linear`) at steps 4 and 7.\n* **KAN variants**: replace `pw1` and `pw2` by `KAN` modules:\n\n  * After LayerNorm, **flatten spatial**: `(N, H, W, C)` → `x_flat (N*H*W, C)`.\n  * `KAN([C → 4C])` processes `x_flat` → `(N*H*W, 4C)` → reshape to `(N,H,W,4C)`.\n  * Activation + GRN as before.\n  * Flatten again and `KAN([4C → C])` → `(N,H,W,C)` → permute back → residual add.\n* **Effectively**: where baseline uses simple linear projection per position, KAN uses a learned spline-based transform (data-adaptive nonlinear mapping) in place of those Linear layers.\n\n---\n\n# Example numeric trace (your config: input 160, dims=(48,96,192,384), depths=(2,2,6,2))\n\n* Input: `(N, 3, 160, 160)`\n* Stem conv (stride 4): `(N, 48, 40, 40)`\n* Stage0 (2 blocks): operate at `(N,48,40,40)`; inside block `pw1` expands → `(N,192,40,40)` then `pw2` compresses back to `(N,48,40,40)`.\n* Downsample → `(N,96,20,20)`\n* Stage1 (2 blocks): `(N,96,20,20)`; `pw1` → `4C=384`, `pw2` → `96`.\n* Downsample → `(N,192,10,10)`\n* Stage2 (6 blocks): `(N,192,10,10)`; `pw1` → `768`, `pw2` → `192`.\n* Downsample → `(N,384,5,5)`\n* Stage3 (2 blocks): `(N,384,5,5)`; `pw1` → `1536`, `pw2` → `384`.\n* Global avg pool → `(N,384)` → head → `(N,num_classes)`.\n\n---\n\n# Variant differences (compact table)\n\n| Variant   |                pw1/pw2 | SE location                                        | Key effect                                                                          |\n| --------- | ---------------------: | -------------------------------------------------- | ----------------------------------------------------------------------------------- |\n| Baseline  |               `Linear` | none                                               | standard ConvNeXtV2 inverted-MLP per position                                       |\n| +SE       |               `Linear` | after `pw2` (block output) before permute/residual | channel gating (squeeze & excite) — rescales channels globally                      |\n| +KAN      | `KAN` (both pw1 & pw2) | none                                               | replaces linear projections with adaptive spline-based transforms (more expressive) |\n| +SE + KAN |             `KAN` + SE | SE after second KAN (same logical place)           | combines KAN expressivity with channel gating                                       |\n\n---\n\n# Short notes on behavior & why placements matter\n\n* **C and per-block expansion (4·C)**: the inverted MLP expands channel dimension (`C → 4C`) so the block can mix channels nonlinearly per spatial position and then project back. KAN performs that same expand/contract but with spline-adaptive mappings.\n* **SE placement**: standard practice is exactly where you used it—on the block *output* channels before adding the residual. It gates the block's produced channel features globally.\n* **Why SE sometimes hurts with KAN**:\n\n  * KAN learns *richer, data-conditioned* mappings. A strong global gating (SE) after KAN can **suppress** those nuanced outputs or create conflicting gradients, reducing the benefit.\n  * SE is a global coarse gate — if KAN encodes fine discriminative features across channels, SE may mistakenly down-weight helpful channels (especially on small/imbalanced datasets).\n* **Memory / compute**: KAN is heavier (it flattens spatial dims and runs more complex `KANLinear` ops). expect more params and higher GPU usage than simple Linear.\n\n---\n\n# Final short guidance\n\n* **Where MLPs are**: inside each block — `pw1` (C→4C) and `pw2` (4C→C).\n* **Where KAN replaces MLPs**: exactly those two spots, applied to flattened `(N*H*W, features)`.\n* **SE belongs after pw2/KAN2 and before residual** (your implementation is correct). Whether SE helps depends on data and interaction with KAN—on your MRI set KAN alone gave the best lift; SE added gating that was redundant or harmful.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}